{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Obed_Rhesa_2101191020.ipynb",
      "provenance": [],
      "mount_file_id": "1Q-izxfnYP46-yk9EI5W_k1CdFvAg-Y12",
      "authorship_tag": "ABX9TyMvHh2uX/aQJIb2UPkKGYD9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XO-ID/UTS_3scene_obed/blob/main/Obed_Rhesa_2101191020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp3C5_w3ebVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a05ccce1-bd48-4de3-c4e6-735fd0910df8"
      },
      "source": [
        "cd /content/drive/MyDrive/UTS-SLO"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/UTS-SLO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7yW-nd6h23B",
        "outputId": "c2768ce8-89e2-4662-ce60-1d62dfcc582a"
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;36m3scene\u001b[0m@  UTS.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11bYOOkvh3hV"
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from PIL import Image\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-bqt5CUmLdz",
        "outputId": "f99adad0-ca43-4496-f73e-160e1dafc29b"
      },
      "source": [
        "# grab all image paths in the input dataset directory, then initialize\n",
        "# our list of images and corresponding class labels\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = paths.list_images(\"3scene\")\n",
        "data = []\n",
        "labels = []"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz7GYOBjn-Ey"
      },
      "source": [
        "# loop over our input images\n",
        "for imagePath in imagePaths:\n",
        "\t# load the input image from disk, resize it to 64x64 pixels, scale\n",
        "\t# the pixel intensities to the range [0, 1], and then update our\n",
        "\t# images list\n",
        "\timage = Image.open(imagePath)\n",
        " #bisa pasang preprocessing disini jika mau, seperti filterring, dll\n",
        "\timage = np.array(image.resize((128, 128))) / 255.0 #normalisasi\n",
        "\tdata.append(image)\n",
        "\n",
        "\t# extract the class label from the file path and update the\n",
        "\t# labels list\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\tlabels.append(label)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAEVa22uu2UN",
        "outputId": "c9f5955d-2e42-4cad-881b-d09eac637a97"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'forest', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'highway', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast', 'coast']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsEQwn0IvBdz"
      },
      "source": [
        "# encode the labels, converting them from strings to integers\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Glg-dGKvEsD",
        "outputId": "1d125f7c-3c9e-469d-8eeb-15981521c27a"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " ...\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtFhb7EvvMpv",
        "outputId": "981db84f-c16a-4d15-a87f-2f199aab8bb9"
      },
      "source": [
        "print(np.array(data).shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(948, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsdUgeOMvPnG",
        "outputId": "b897effe-4ab5-4d38-f94a-cf6cefcd2d58"
      },
      "source": [
        "# perform a training and testing split, using 75% of the data for\n",
        "# training and 25% for evaluation\n",
        "(trainX, testX, trainY, testY) = train_test_split(np.array(data),\tnp.array(labels), test_size=0.25)\n",
        "print(trainX.shape)\n",
        "print(testX.shape)\n",
        "print(trainY.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(711, 128, 128, 3)\n",
            "(237, 128, 128, 3)\n",
            "(711, 3)\n",
            "(237, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjd_h7K4T1aL",
        "outputId": "957dcd56-e8ae-45a6-b95c-846feddbbd26"
      },
      "source": [
        "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)\n",
        "print(base_model.summary())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPMQs6RUvQyB"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense, Dropout\n",
        "\n",
        "#model = Sequential(\n",
        "    #[\n",
        "        #Flatten(input_shape=(128*128*3,)),\n",
        "        #Dense(256, activation=\"relu\"),\n",
        "        #Dense(128, activation=\"relu\"),\n",
        "        #Dropout(0.3),\n",
        "        #Dense(64, activation=\"relu\"),\n",
        "        #Dense(32, activation=\"relu\"),\n",
        "        #Dropout(0.3),\n",
        "        #Dense(16, activation=\"relu\"),\n",
        "        #Dense(8, activation=\"sigmoid\"),\n",
        "        #Dense(3, activation = \"softmax\"),\n",
        "    #]\n",
        "#)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ7swM1dUf8T"
      },
      "source": [
        "x = base_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "preds = tf.keras.layers.Dense(3, activation ='softmax')(x)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVOMKwFLvUGy",
        "outputId": "40f06994-7d8c-47a4-a547-c4008102843b"
      },
      "source": [
        "model = tf.keras.models.Model(inputs=base_model.input, outputs=preds)\n",
        "print(model.summary())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          262272      global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          16512       dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          16512       dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           8256        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 3)            195         dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,891,459\n",
            "Trainable params: 23,838,339\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnIRqi-uvWxh",
        "outputId": "ba09fd41-9619-46b7-cd2b-b4458846abfd"
      },
      "source": [
        "# train the model using the Adam optimizer\n",
        "print(\"[INFO] training network...\")\n",
        "opt = Adam(lr=1e-2, decay=1e-3)\n",
        "#opt = optimizers.SGD(lr=0.01, decay=1e-2/50, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPCfSn7wvZSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b52387-83da-4061-88f8-262299a4a5f7"
      },
      "source": [
        "#trainY\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=1000, batch_size=56)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "13/13 [==============================] - 15s 458ms/step - loss: 2.5239 - accuracy: 0.3594 - val_loss: 2034997934998515875840.0000 - val_accuracy: 0.3797\n",
            "Epoch 2/1000\n",
            "13/13 [==============================] - 3s 215ms/step - loss: 1.0258 - accuracy: 0.5371 - val_loss: 391920362717184.0000 - val_accuracy: 0.3797\n",
            "Epoch 3/1000\n",
            "13/13 [==============================] - 3s 217ms/step - loss: 0.8953 - accuracy: 0.5773 - val_loss: 12862960640.0000 - val_accuracy: 0.3797\n",
            "Epoch 4/1000\n",
            "13/13 [==============================] - 3s 217ms/step - loss: 0.6818 - accuracy: 0.7213 - val_loss: 14775049.0000 - val_accuracy: 0.3797\n",
            "Epoch 5/1000\n",
            "13/13 [==============================] - 3s 218ms/step - loss: 0.5371 - accuracy: 0.7837 - val_loss: 88918.0391 - val_accuracy: 0.3797\n",
            "Epoch 6/1000\n",
            "13/13 [==============================] - 3s 219ms/step - loss: 0.6119 - accuracy: 0.7360 - val_loss: 20617.8203 - val_accuracy: 0.3038\n",
            "Epoch 7/1000\n",
            "13/13 [==============================] - 3s 219ms/step - loss: 0.6956 - accuracy: 0.6975 - val_loss: 2.5905 - val_accuracy: 0.3165\n",
            "Epoch 8/1000\n",
            "13/13 [==============================] - 3s 218ms/step - loss: 0.5971 - accuracy: 0.7642 - val_loss: 3.3825 - val_accuracy: 0.3165\n",
            "Epoch 9/1000\n",
            "13/13 [==============================] - 3s 220ms/step - loss: 0.4043 - accuracy: 0.8199 - val_loss: 3.4690 - val_accuracy: 0.3165\n",
            "Epoch 10/1000\n",
            "13/13 [==============================] - 3s 219ms/step - loss: 0.4906 - accuracy: 0.7933 - val_loss: 1135.0739 - val_accuracy: 0.3038\n",
            "Epoch 11/1000\n",
            "13/13 [==============================] - 3s 219ms/step - loss: 0.4525 - accuracy: 0.8079 - val_loss: 108.7953 - val_accuracy: 0.3038\n",
            "Epoch 12/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.3473 - accuracy: 0.8616 - val_loss: 8.0093 - val_accuracy: 0.4430\n",
            "Epoch 13/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.3797 - accuracy: 0.8486 - val_loss: 14.6756 - val_accuracy: 0.3797\n",
            "Epoch 14/1000\n",
            "13/13 [==============================] - 3s 220ms/step - loss: 0.4860 - accuracy: 0.7721 - val_loss: 2.8420 - val_accuracy: 0.3797\n",
            "Epoch 15/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.3179 - accuracy: 0.8589 - val_loss: 14.1674 - val_accuracy: 0.3797\n",
            "Epoch 16/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5275 - accuracy: 0.7488 - val_loss: 1.2996 - val_accuracy: 0.5359\n",
            "Epoch 17/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5171 - accuracy: 0.7855 - val_loss: 114.6817 - val_accuracy: 0.3038\n",
            "Epoch 18/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.3906 - accuracy: 0.8246 - val_loss: 142.8277 - val_accuracy: 0.3038\n",
            "Epoch 19/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.2806 - accuracy: 0.8623 - val_loss: 39.8412 - val_accuracy: 0.3165\n",
            "Epoch 20/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.3475 - accuracy: 0.8419 - val_loss: 6.5391 - val_accuracy: 0.3586\n",
            "Epoch 21/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.3965 - accuracy: 0.8248 - val_loss: 4.4098 - val_accuracy: 0.4093\n",
            "Epoch 22/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3287 - accuracy: 0.8618 - val_loss: 18.7375 - val_accuracy: 0.3080\n",
            "Epoch 23/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3006 - accuracy: 0.8762 - val_loss: 8.7197 - val_accuracy: 0.3797\n",
            "Epoch 24/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.2324 - accuracy: 0.9220 - val_loss: 1.4419 - val_accuracy: 0.6034\n",
            "Epoch 25/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.2378 - accuracy: 0.9011 - val_loss: 2.9009 - val_accuracy: 0.2532\n",
            "Epoch 26/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.2136 - accuracy: 0.9135 - val_loss: 11.4027 - val_accuracy: 0.3797\n",
            "Epoch 27/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.2408 - accuracy: 0.9008 - val_loss: 2.8089 - val_accuracy: 0.4219\n",
            "Epoch 28/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.1687 - accuracy: 0.9310 - val_loss: 5.8838 - val_accuracy: 0.3165\n",
            "Epoch 29/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.2316 - accuracy: 0.9191 - val_loss: 1.0821 - val_accuracy: 0.5907\n",
            "Epoch 30/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.1892 - accuracy: 0.9337 - val_loss: 4.2341 - val_accuracy: 0.3418\n",
            "Epoch 31/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.1666 - accuracy: 0.9411 - val_loss: 4.9986 - val_accuracy: 0.3291\n",
            "Epoch 32/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.1928 - accuracy: 0.9379 - val_loss: 0.8680 - val_accuracy: 0.6245\n",
            "Epoch 33/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.1614 - accuracy: 0.9510 - val_loss: 1.0709 - val_accuracy: 0.5654\n",
            "Epoch 34/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.1290 - accuracy: 0.9674 - val_loss: 0.9106 - val_accuracy: 0.5654\n",
            "Epoch 35/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.1813 - accuracy: 0.9374 - val_loss: 1.9249 - val_accuracy: 0.3797\n",
            "Epoch 36/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.1935 - accuracy: 0.9266 - val_loss: 3.1800 - val_accuracy: 0.3418\n",
            "Epoch 37/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.1737 - accuracy: 0.9359 - val_loss: 0.7630 - val_accuracy: 0.5654\n",
            "Epoch 38/1000\n",
            "13/13 [==============================] - 3s 220ms/step - loss: 0.2071 - accuracy: 0.9311 - val_loss: 1.3103 - val_accuracy: 0.5485\n",
            "Epoch 39/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.1457 - accuracy: 0.9532 - val_loss: 1.2803 - val_accuracy: 0.5949\n",
            "Epoch 40/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.1185 - accuracy: 0.9497 - val_loss: 1.5010 - val_accuracy: 0.4599\n",
            "Epoch 41/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.1489 - accuracy: 0.9444 - val_loss: 1.3481 - val_accuracy: 0.5232\n",
            "Epoch 42/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.1151 - accuracy: 0.9631 - val_loss: 2.1587 - val_accuracy: 0.4008\n",
            "Epoch 43/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.1121 - accuracy: 0.9518 - val_loss: 1.0458 - val_accuracy: 0.5823\n",
            "Epoch 44/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.1499 - accuracy: 0.9464 - val_loss: 1.5968 - val_accuracy: 0.4473\n",
            "Epoch 45/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0951 - accuracy: 0.9703 - val_loss: 0.8051 - val_accuracy: 0.5696\n",
            "Epoch 46/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.1069 - accuracy: 0.9713 - val_loss: 2.7697 - val_accuracy: 0.5316\n",
            "Epoch 47/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.1633 - accuracy: 0.9586 - val_loss: 0.5969 - val_accuracy: 0.7342\n",
            "Epoch 48/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.1044 - accuracy: 0.9630 - val_loss: 0.5672 - val_accuracy: 0.8017\n",
            "Epoch 49/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0852 - accuracy: 0.9635 - val_loss: 0.6216 - val_accuracy: 0.7131\n",
            "Epoch 50/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0570 - accuracy: 0.9822 - val_loss: 0.8040 - val_accuracy: 0.6624\n",
            "Epoch 51/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0776 - accuracy: 0.9724 - val_loss: 0.6523 - val_accuracy: 0.6751\n",
            "Epoch 52/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0897 - accuracy: 0.9642 - val_loss: 0.8265 - val_accuracy: 0.6498\n",
            "Epoch 53/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0839 - accuracy: 0.9669 - val_loss: 0.6034 - val_accuracy: 0.7553\n",
            "Epoch 54/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0477 - accuracy: 0.9806 - val_loss: 0.9636 - val_accuracy: 0.7426\n",
            "Epoch 55/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0657 - accuracy: 0.9833 - val_loss: 0.6947 - val_accuracy: 0.7722\n",
            "Epoch 56/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0812 - accuracy: 0.9725 - val_loss: 1.2800 - val_accuracy: 0.6835\n",
            "Epoch 57/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.1006 - accuracy: 0.9698 - val_loss: 3.6813 - val_accuracy: 0.4515\n",
            "Epoch 58/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0711 - accuracy: 0.9799 - val_loss: 1.3105 - val_accuracy: 0.6371\n",
            "Epoch 59/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0589 - accuracy: 0.9829 - val_loss: 0.9943 - val_accuracy: 0.6878\n",
            "Epoch 60/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0584 - accuracy: 0.9848 - val_loss: 1.6382 - val_accuracy: 0.7300\n",
            "Epoch 61/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0782 - accuracy: 0.9705 - val_loss: 1.5893 - val_accuracy: 0.7384\n",
            "Epoch 62/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.1424 - accuracy: 0.9511 - val_loss: 0.6609 - val_accuracy: 0.8776\n",
            "Epoch 63/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0992 - accuracy: 0.9622 - val_loss: 1.8168 - val_accuracy: 0.7004\n",
            "Epoch 64/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0429 - accuracy: 0.9877 - val_loss: 1.0100 - val_accuracy: 0.8017\n",
            "Epoch 65/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0315 - accuracy: 0.9892 - val_loss: 1.1771 - val_accuracy: 0.8186\n",
            "Epoch 66/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0626 - accuracy: 0.9748 - val_loss: 1.8647 - val_accuracy: 0.7975\n",
            "Epoch 67/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0610 - accuracy: 0.9830 - val_loss: 0.5084 - val_accuracy: 0.8692\n",
            "Epoch 68/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0663 - accuracy: 0.9751 - val_loss: 0.7574 - val_accuracy: 0.8523\n",
            "Epoch 69/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0282 - accuracy: 0.9886 - val_loss: 0.7933 - val_accuracy: 0.8819\n",
            "Epoch 70/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 0.6368 - val_accuracy: 0.9156\n",
            "Epoch 71/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.4778 - val_accuracy: 0.9072\n",
            "Epoch 72/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0349 - accuracy: 0.9883 - val_loss: 3.5326 - val_accuracy: 0.7300\n",
            "Epoch 73/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0595 - accuracy: 0.9763 - val_loss: 8.6007 - val_accuracy: 0.5190\n",
            "Epoch 74/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0666 - accuracy: 0.9735 - val_loss: 3.5288 - val_accuracy: 0.5485\n",
            "Epoch 75/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0632 - accuracy: 0.9787 - val_loss: 0.9216 - val_accuracy: 0.8692\n",
            "Epoch 76/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0221 - accuracy: 0.9974 - val_loss: 0.7540 - val_accuracy: 0.9198\n",
            "Epoch 77/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0519 - accuracy: 0.9844 - val_loss: 0.7636 - val_accuracy: 0.8692\n",
            "Epoch 78/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0520 - accuracy: 0.9798 - val_loss: 0.4258 - val_accuracy: 0.8987\n",
            "Epoch 79/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0334 - accuracy: 0.9885 - val_loss: 0.5597 - val_accuracy: 0.8945\n",
            "Epoch 80/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0405 - accuracy: 0.9908 - val_loss: 1.1984 - val_accuracy: 0.7975\n",
            "Epoch 81/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0525 - accuracy: 0.9766 - val_loss: 0.5140 - val_accuracy: 0.8734\n",
            "Epoch 82/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0515 - accuracy: 0.9856 - val_loss: 0.4285 - val_accuracy: 0.8776\n",
            "Epoch 83/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0278 - accuracy: 0.9888 - val_loss: 1.4683 - val_accuracy: 0.7806\n",
            "Epoch 84/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0227 - accuracy: 0.9904 - val_loss: 0.8667 - val_accuracy: 0.8481\n",
            "Epoch 85/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0260 - accuracy: 0.9893 - val_loss: 1.5524 - val_accuracy: 0.7004\n",
            "Epoch 86/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0373 - accuracy: 0.9927 - val_loss: 0.5915 - val_accuracy: 0.8987\n",
            "Epoch 87/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0198 - accuracy: 0.9919 - val_loss: 0.4369 - val_accuracy: 0.9156\n",
            "Epoch 88/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0121 - accuracy: 0.9977 - val_loss: 0.5736 - val_accuracy: 0.8861\n",
            "Epoch 89/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0395 - accuracy: 0.9853 - val_loss: 0.8779 - val_accuracy: 0.8439\n",
            "Epoch 90/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0368 - accuracy: 0.9895 - val_loss: 1.1596 - val_accuracy: 0.7890\n",
            "Epoch 91/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0301 - accuracy: 0.9915 - val_loss: 0.8105 - val_accuracy: 0.8059\n",
            "Epoch 92/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0282 - accuracy: 0.9947 - val_loss: 0.5418 - val_accuracy: 0.8608\n",
            "Epoch 93/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0454 - accuracy: 0.9796 - val_loss: 0.4385 - val_accuracy: 0.8650\n",
            "Epoch 94/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0155 - accuracy: 0.9977 - val_loss: 0.5281 - val_accuracy: 0.8734\n",
            "Epoch 95/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0077 - accuracy: 0.9965 - val_loss: 0.4709 - val_accuracy: 0.9156\n",
            "Epoch 96/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.5095 - val_accuracy: 0.8903\n",
            "Epoch 97/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0137 - accuracy: 0.9941 - val_loss: 0.5510 - val_accuracy: 0.8650\n",
            "Epoch 98/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.5746 - val_accuracy: 0.8861\n",
            "Epoch 99/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0134 - accuracy: 0.9907 - val_loss: 0.6181 - val_accuracy: 0.8734\n",
            "Epoch 100/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.6489 - val_accuracy: 0.8945\n",
            "Epoch 101/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6333 - val_accuracy: 0.9072\n",
            "Epoch 102/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 9.0591e-04 - accuracy: 1.0000 - val_loss: 0.7555 - val_accuracy: 0.9030\n",
            "Epoch 103/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0043 - accuracy: 0.9971 - val_loss: 0.7665 - val_accuracy: 0.8987\n",
            "Epoch 104/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 7.5792e-04 - accuracy: 1.0000 - val_loss: 0.7517 - val_accuracy: 0.9030\n",
            "Epoch 105/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7293 - val_accuracy: 0.8987\n",
            "Epoch 106/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 2.9293e-04 - accuracy: 1.0000 - val_loss: 0.6823 - val_accuracy: 0.9030\n",
            "Epoch 107/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 1.1958e-04 - accuracy: 1.0000 - val_loss: 0.6705 - val_accuracy: 0.9156\n",
            "Epoch 108/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 9.0790e-05 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 0.9156\n",
            "Epoch 109/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 1.0982e-04 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.9156\n",
            "Epoch 110/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.6426e-04 - accuracy: 1.0000 - val_loss: 0.7902 - val_accuracy: 0.9114\n",
            "Epoch 111/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0218 - accuracy: 0.9957 - val_loss: 1.8677 - val_accuracy: 0.7975\n",
            "Epoch 112/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0705 - accuracy: 0.9878 - val_loss: 0.9695 - val_accuracy: 0.8397\n",
            "Epoch 113/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0591 - accuracy: 0.9783 - val_loss: 0.5947 - val_accuracy: 0.8354\n",
            "Epoch 114/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0327 - accuracy: 0.9900 - val_loss: 0.5095 - val_accuracy: 0.8565\n",
            "Epoch 115/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 0.4407 - val_accuracy: 0.8734\n",
            "Epoch 116/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.5052 - val_accuracy: 0.8945\n",
            "Epoch 117/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0088 - accuracy: 0.9964 - val_loss: 0.9405 - val_accuracy: 0.8397\n",
            "Epoch 118/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.5438 - val_accuracy: 0.9114\n",
            "Epoch 119/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 1.0010 - val_accuracy: 0.8270\n",
            "Epoch 120/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.7775 - val_accuracy: 0.8861\n",
            "Epoch 121/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7649 - val_accuracy: 0.9072\n",
            "Epoch 122/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.9114\n",
            "Epoch 123/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0036 - accuracy: 0.9972 - val_loss: 0.5174 - val_accuracy: 0.8945\n",
            "Epoch 124/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8334 - val_accuracy: 0.8565\n",
            "Epoch 125/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 1.3961 - val_accuracy: 0.7848\n",
            "Epoch 126/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0482 - val_accuracy: 0.8523\n",
            "Epoch 127/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 4.9688e-04 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.8945\n",
            "Epoch 128/1000\n",
            "13/13 [==============================] - 3s 220ms/step - loss: 7.1464e-04 - accuracy: 1.0000 - val_loss: 0.6076 - val_accuracy: 0.9072\n",
            "Epoch 129/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 0.5881 - val_accuracy: 0.9114\n",
            "Epoch 130/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 9.0773e-04 - accuracy: 0.9994 - val_loss: 0.7952 - val_accuracy: 0.8903\n",
            "Epoch 131/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3202 - val_accuracy: 0.8776\n",
            "Epoch 132/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8705 - val_accuracy: 0.8397\n",
            "Epoch 133/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 7.6817e-04 - accuracy: 1.0000 - val_loss: 1.3824 - val_accuracy: 0.8608\n",
            "Epoch 134/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0346 - accuracy: 0.9923 - val_loss: 1.5036 - val_accuracy: 0.7890\n",
            "Epoch 135/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0338 - accuracy: 0.9912 - val_loss: 1.1486 - val_accuracy: 0.7890\n",
            "Epoch 136/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0392 - accuracy: 0.9844 - val_loss: 0.7003 - val_accuracy: 0.8650\n",
            "Epoch 137/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0453 - accuracy: 0.9894 - val_loss: 0.5105 - val_accuracy: 0.9198\n",
            "Epoch 138/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 1.5577 - val_accuracy: 0.7722\n",
            "Epoch 139/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0211 - accuracy: 0.9943 - val_loss: 0.5440 - val_accuracy: 0.9072\n",
            "Epoch 140/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.7247 - val_accuracy: 0.8945\n",
            "Epoch 141/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0072 - accuracy: 0.9971 - val_loss: 0.8377 - val_accuracy: 0.9030\n",
            "Epoch 142/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0111 - accuracy: 0.9955 - val_loss: 0.9035 - val_accuracy: 0.8523\n",
            "Epoch 143/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9238 - val_accuracy: 0.8692\n",
            "Epoch 144/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 6.4265e-04 - accuracy: 1.0000 - val_loss: 0.8787 - val_accuracy: 0.8819\n",
            "Epoch 145/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8005 - val_accuracy: 0.8903\n",
            "Epoch 146/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.6834e-04 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.9114\n",
            "Epoch 147/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.8713e-04 - accuracy: 1.0000 - val_loss: 0.7365 - val_accuracy: 0.9072\n",
            "Epoch 148/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.8470 - val_accuracy: 0.8987\n",
            "Epoch 149/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0325 - accuracy: 0.9940 - val_loss: 0.8681 - val_accuracy: 0.8734\n",
            "Epoch 150/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 2.0440 - val_accuracy: 0.7848\n",
            "Epoch 151/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0079 - accuracy: 0.9993 - val_loss: 1.0608 - val_accuracy: 0.8481\n",
            "Epoch 152/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 1.0209 - val_accuracy: 0.8819\n",
            "Epoch 153/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 1.2369 - val_accuracy: 0.8776\n",
            "Epoch 154/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9057 - val_accuracy: 0.8692\n",
            "Epoch 155/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 6.6457e-04 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8903\n",
            "Epoch 156/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 8.5479e-04 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.9114\n",
            "Epoch 157/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.5392e-04 - accuracy: 1.0000 - val_loss: 0.8060 - val_accuracy: 0.9198\n",
            "Epoch 158/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.8254 - val_accuracy: 0.9030\n",
            "Epoch 159/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.7210 - val_accuracy: 0.9030\n",
            "Epoch 160/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 2.5223e-04 - accuracy: 1.0000 - val_loss: 0.6600 - val_accuracy: 0.9030\n",
            "Epoch 161/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.3456e-04 - accuracy: 1.0000 - val_loss: 0.6763 - val_accuracy: 0.8987\n",
            "Epoch 162/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 1.3333e-04 - accuracy: 1.0000 - val_loss: 0.7169 - val_accuracy: 0.8987\n",
            "Epoch 163/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 6.0774e-05 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8945\n",
            "Epoch 164/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 4.5314e-04 - accuracy: 1.0000 - val_loss: 0.7416 - val_accuracy: 0.8945\n",
            "Epoch 165/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.4225e-05 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.8987\n",
            "Epoch 166/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.5901 - val_accuracy: 0.8861\n",
            "Epoch 167/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 0.9429 - val_accuracy: 0.8523\n",
            "Epoch 168/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0317 - accuracy: 0.9928 - val_loss: 0.7087 - val_accuracy: 0.8608\n",
            "Epoch 169/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.4735 - val_accuracy: 0.9030\n",
            "Epoch 170/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0149 - accuracy: 0.9965 - val_loss: 0.5227 - val_accuracy: 0.8819\n",
            "Epoch 171/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.6049 - val_accuracy: 0.8945\n",
            "Epoch 172/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0066 - accuracy: 0.9973 - val_loss: 0.7943 - val_accuracy: 0.8861\n",
            "Epoch 173/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0181 - accuracy: 0.9911 - val_loss: 0.9383 - val_accuracy: 0.8776\n",
            "Epoch 174/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0030 - accuracy: 0.9974 - val_loss: 0.5504 - val_accuracy: 0.9072\n",
            "Epoch 175/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5159 - val_accuracy: 0.9241\n",
            "Epoch 176/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 24.8488 - val_accuracy: 0.4895\n",
            "Epoch 177/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0112 - accuracy: 0.9940 - val_loss: 1.4932 - val_accuracy: 0.7890\n",
            "Epoch 178/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0094 - accuracy: 0.9962 - val_loss: 0.7430 - val_accuracy: 0.8903\n",
            "Epoch 179/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6446 - val_accuracy: 0.8987\n",
            "Epoch 180/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.6011 - val_accuracy: 0.9072\n",
            "Epoch 181/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 8.2792e-04 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 0.8861\n",
            "Epoch 182/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.3890e-04 - accuracy: 1.0000 - val_loss: 0.6241 - val_accuracy: 0.8987\n",
            "Epoch 183/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0011 - accuracy: 0.9991 - val_loss: 0.5286 - val_accuracy: 0.9198\n",
            "Epoch 184/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0032 - accuracy: 0.9978 - val_loss: 0.6683 - val_accuracy: 0.8987\n",
            "Epoch 185/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.5019 - val_accuracy: 0.9156\n",
            "Epoch 186/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.6590 - val_accuracy: 0.9325\n",
            "Epoch 187/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0116 - accuracy: 0.9943 - val_loss: 0.8443 - val_accuracy: 0.9198\n",
            "Epoch 188/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 1.5289 - val_accuracy: 0.6962\n",
            "Epoch 189/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.7553 - val_accuracy: 0.8565\n",
            "Epoch 190/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 4.2473e-04 - accuracy: 1.0000 - val_loss: 0.9320 - val_accuracy: 0.8650\n",
            "Epoch 191/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6563 - val_accuracy: 0.8903\n",
            "Epoch 192/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 4.5445e-04 - accuracy: 1.0000 - val_loss: 0.5866 - val_accuracy: 0.9072\n",
            "Epoch 193/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.9072\n",
            "Epoch 194/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.4817e-04 - accuracy: 1.0000 - val_loss: 0.5844 - val_accuracy: 0.9114\n",
            "Epoch 195/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.5943e-04 - accuracy: 1.0000 - val_loss: 0.5544 - val_accuracy: 0.9114\n",
            "Epoch 196/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0018 - accuracy: 0.9985 - val_loss: 0.5655 - val_accuracy: 0.9241\n",
            "Epoch 197/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.1927e-04 - accuracy: 1.0000 - val_loss: 0.6416 - val_accuracy: 0.9198\n",
            "Epoch 198/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.7853e-05 - accuracy: 1.0000 - val_loss: 0.6630 - val_accuracy: 0.9198\n",
            "Epoch 199/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 6.2579e-05 - accuracy: 1.0000 - val_loss: 0.6619 - val_accuracy: 0.9241\n",
            "Epoch 200/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 1.3073e-04 - accuracy: 1.0000 - val_loss: 0.6535 - val_accuracy: 0.9241\n",
            "Epoch 201/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 5.5341e-05 - accuracy: 1.0000 - val_loss: 0.6480 - val_accuracy: 0.9241\n",
            "Epoch 202/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.8400e-05 - accuracy: 1.0000 - val_loss: 0.6420 - val_accuracy: 0.9241\n",
            "Epoch 203/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.8194e-05 - accuracy: 1.0000 - val_loss: 0.6399 - val_accuracy: 0.9241\n",
            "Epoch 204/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.5972e-05 - accuracy: 1.0000 - val_loss: 0.6339 - val_accuracy: 0.9241\n",
            "Epoch 205/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.4118e-05 - accuracy: 1.0000 - val_loss: 0.6232 - val_accuracy: 0.9325\n",
            "Epoch 206/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.0964e-04 - accuracy: 1.0000 - val_loss: 0.6150 - val_accuracy: 0.9325\n",
            "Epoch 207/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.2041e-05 - accuracy: 1.0000 - val_loss: 0.6134 - val_accuracy: 0.9325\n",
            "Epoch 208/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.9818e-04 - accuracy: 1.0000 - val_loss: 0.6166 - val_accuracy: 0.9325\n",
            "Epoch 209/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 6.2756e-05 - accuracy: 1.0000 - val_loss: 0.6213 - val_accuracy: 0.9325\n",
            "Epoch 210/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 8.7502e-05 - accuracy: 1.0000 - val_loss: 0.6409 - val_accuracy: 0.9325\n",
            "Epoch 211/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.6872e-05 - accuracy: 1.0000 - val_loss: 0.6496 - val_accuracy: 0.9325\n",
            "Epoch 212/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.4522e-04 - accuracy: 1.0000 - val_loss: 0.6100 - val_accuracy: 0.9325\n",
            "Epoch 213/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 5.8604e-05 - accuracy: 1.0000 - val_loss: 0.5857 - val_accuracy: 0.9367\n",
            "Epoch 214/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 9.8663e-06 - accuracy: 1.0000 - val_loss: 0.5851 - val_accuracy: 0.9367\n",
            "Epoch 215/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 1.3623e-05 - accuracy: 1.0000 - val_loss: 0.5902 - val_accuracy: 0.9367\n",
            "Epoch 216/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.2902e-04 - accuracy: 1.0000 - val_loss: 0.6075 - val_accuracy: 0.9325\n",
            "Epoch 217/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 2.5702e-05 - accuracy: 1.0000 - val_loss: 0.6136 - val_accuracy: 0.9325\n",
            "Epoch 218/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.6413e-05 - accuracy: 1.0000 - val_loss: 0.6092 - val_accuracy: 0.9325\n",
            "Epoch 219/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.1780e-06 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.9325\n",
            "Epoch 220/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0216 - accuracy: 0.9962 - val_loss: 6.6920 - val_accuracy: 0.6878\n",
            "Epoch 221/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.2511 - accuracy: 0.9553 - val_loss: 4.8891 - val_accuracy: 0.3966\n",
            "Epoch 222/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.1232 - accuracy: 0.9678 - val_loss: 3.6482 - val_accuracy: 0.4093\n",
            "Epoch 223/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0293 - accuracy: 0.9926 - val_loss: 4.7800 - val_accuracy: 0.3840\n",
            "Epoch 224/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 1.4760 - val_accuracy: 0.6920\n",
            "Epoch 225/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 2.9643 - val_accuracy: 0.5063\n",
            "Epoch 226/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0278 - accuracy: 0.9943 - val_loss: 1.2639 - val_accuracy: 0.7300\n",
            "Epoch 227/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.5565 - val_accuracy: 0.9030\n",
            "Epoch 228/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0104 - accuracy: 0.9978 - val_loss: 0.5762 - val_accuracy: 0.9156\n",
            "Epoch 229/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.5665 - val_accuracy: 0.8987\n",
            "Epoch 230/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5813 - val_accuracy: 0.8903\n",
            "Epoch 231/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.5516 - val_accuracy: 0.8945\n",
            "Epoch 232/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.1977e-04 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.8650\n",
            "Epoch 233/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.6600 - val_accuracy: 0.8565\n",
            "Epoch 234/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6731 - val_accuracy: 0.8987\n",
            "Epoch 235/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0695 - val_accuracy: 0.8903\n",
            "Epoch 236/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 5.1825e-04 - accuracy: 1.0000 - val_loss: 1.1156 - val_accuracy: 0.8945\n",
            "Epoch 237/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.9283\n",
            "Epoch 238/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.8255 - val_accuracy: 0.9198\n",
            "Epoch 239/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.7470e-04 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.9241\n",
            "Epoch 240/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 1.4363 - val_accuracy: 0.8861\n",
            "Epoch 241/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0272 - accuracy: 0.9967 - val_loss: 1.0356 - val_accuracy: 0.8861\n",
            "Epoch 242/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.5933 - val_accuracy: 0.9030\n",
            "Epoch 243/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 1.2327 - val_accuracy: 0.8861\n",
            "Epoch 244/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.9472 - val_accuracy: 0.8987\n",
            "Epoch 245/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0170 - accuracy: 0.9971 - val_loss: 0.7344 - val_accuracy: 0.8650\n",
            "Epoch 246/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.5192 - val_accuracy: 0.9030\n",
            "Epoch 247/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.5209 - val_accuracy: 0.9325\n",
            "Epoch 248/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0130 - accuracy: 0.9948 - val_loss: 1.6604 - val_accuracy: 0.7975\n",
            "Epoch 249/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 3.6784 - val_accuracy: 0.7089\n",
            "Epoch 250/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 3.8815 - val_accuracy: 0.7342\n",
            "Epoch 251/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 3.2405 - val_accuracy: 0.7932\n",
            "Epoch 252/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 1.0683 - val_accuracy: 0.9283\n",
            "Epoch 253/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.9538 - val_accuracy: 0.9072\n",
            "Epoch 254/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0519 - accuracy: 0.9819 - val_loss: 0.9583 - val_accuracy: 0.8650\n",
            "Epoch 255/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6309 - val_accuracy: 0.8819\n",
            "Epoch 256/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6691 - val_accuracy: 0.9072\n",
            "Epoch 257/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0043 - accuracy: 0.9971 - val_loss: 0.8786 - val_accuracy: 0.9114\n",
            "Epoch 258/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.9782 - val_accuracy: 0.9114\n",
            "Epoch 259/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 1.7245 - val_accuracy: 0.8650\n",
            "Epoch 260/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 4.0790 - val_accuracy: 0.6456\n",
            "Epoch 261/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.8748 - val_accuracy: 0.7426\n",
            "Epoch 262/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8128 - val_accuracy: 0.8397\n",
            "Epoch 263/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.8742 - val_accuracy: 0.9283\n",
            "Epoch 264/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.9498e-04 - accuracy: 1.0000 - val_loss: 0.7623 - val_accuracy: 0.9325\n",
            "Epoch 265/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.8477 - val_accuracy: 0.9367\n",
            "Epoch 266/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 5.6194e-04 - accuracy: 1.0000 - val_loss: 0.8588 - val_accuracy: 0.9156\n",
            "Epoch 267/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 9.8253e-05 - accuracy: 1.0000 - val_loss: 0.8317 - val_accuracy: 0.9198\n",
            "Epoch 268/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.3235e-05 - accuracy: 1.0000 - val_loss: 0.8138 - val_accuracy: 0.9198\n",
            "Epoch 269/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0165 - accuracy: 0.9985 - val_loss: 0.5911 - val_accuracy: 0.8861\n",
            "Epoch 270/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0117 - accuracy: 0.9943 - val_loss: 0.9616 - val_accuracy: 0.8523\n",
            "Epoch 271/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 1.9453 - val_accuracy: 0.8059\n",
            "Epoch 272/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.4105e-04 - accuracy: 0.9998 - val_loss: 2.1153 - val_accuracy: 0.7848\n",
            "Epoch 273/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 1.3171 - val_accuracy: 0.7342\n",
            "Epoch 274/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 1.0771 - val_accuracy: 0.8270\n",
            "Epoch 275/1000\n",
            "13/13 [==============================] - 3s 220ms/step - loss: 0.0113 - accuracy: 0.9937 - val_loss: 0.4775 - val_accuracy: 0.9241\n",
            "Epoch 276/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.4917 - val_accuracy: 0.9198\n",
            "Epoch 277/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.6697 - val_accuracy: 0.9156\n",
            "Epoch 278/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0025 - accuracy: 0.9982 - val_loss: 0.8539 - val_accuracy: 0.9030\n",
            "Epoch 279/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.7367e-04 - accuracy: 1.0000 - val_loss: 0.8855 - val_accuracy: 0.9030\n",
            "Epoch 280/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.6305e-04 - accuracy: 1.0000 - val_loss: 0.8841 - val_accuracy: 0.9030\n",
            "Epoch 281/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9491 - val_accuracy: 0.8945\n",
            "Epoch 282/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9765 - val_accuracy: 0.9072\n",
            "Epoch 283/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0031 - accuracy: 0.9977 - val_loss: 0.8368 - val_accuracy: 0.9156\n",
            "Epoch 284/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0033 - accuracy: 0.9978 - val_loss: 0.5285 - val_accuracy: 0.8861\n",
            "Epoch 285/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.5299 - val_accuracy: 0.8819\n",
            "Epoch 286/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 1.9700 - val_accuracy: 0.7764\n",
            "Epoch 287/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 4.4566 - val_accuracy: 0.6414\n",
            "Epoch 288/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 1.7686 - val_accuracy: 0.8101\n",
            "Epoch 289/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0081 - accuracy: 0.9959 - val_loss: 1.0580 - val_accuracy: 0.8945\n",
            "Epoch 290/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0033 - accuracy: 0.9978 - val_loss: 1.2615 - val_accuracy: 0.8903\n",
            "Epoch 291/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 5.6000e-04 - accuracy: 1.0000 - val_loss: 1.2661 - val_accuracy: 0.8945\n",
            "Epoch 292/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 4.9329e-04 - accuracy: 1.0000 - val_loss: 1.1773 - val_accuracy: 0.8987\n",
            "Epoch 293/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.5145e-04 - accuracy: 1.0000 - val_loss: 1.0781 - val_accuracy: 0.9114\n",
            "Epoch 294/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.5709e-04 - accuracy: 1.0000 - val_loss: 1.0110 - val_accuracy: 0.9198\n",
            "Epoch 295/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0035 - accuracy: 0.9976 - val_loss: 1.5227 - val_accuracy: 0.8608\n",
            "Epoch 296/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0064 - accuracy: 0.9958 - val_loss: 0.7980 - val_accuracy: 0.9241\n",
            "Epoch 297/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0140 - accuracy: 0.9943 - val_loss: 0.5291 - val_accuracy: 0.8987\n",
            "Epoch 298/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0358 - accuracy: 0.9930 - val_loss: 0.6217 - val_accuracy: 0.9156\n",
            "Epoch 299/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0041 - accuracy: 0.9978 - val_loss: 0.6145 - val_accuracy: 0.9156\n",
            "Epoch 300/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.4857 - val_accuracy: 0.9241\n",
            "Epoch 301/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 0.4341 - val_accuracy: 0.9198\n",
            "Epoch 302/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.5649 - val_accuracy: 0.9072\n",
            "Epoch 303/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0226 - accuracy: 0.9900 - val_loss: 1.9308 - val_accuracy: 0.8017\n",
            "Epoch 304/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0166 - accuracy: 0.9926 - val_loss: 1.7196 - val_accuracy: 0.7890\n",
            "Epoch 305/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.2295 - val_accuracy: 0.8439\n",
            "Epoch 306/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1926 - val_accuracy: 0.8565\n",
            "Epoch 307/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 4.9087e-04 - accuracy: 1.0000 - val_loss: 1.1437 - val_accuracy: 0.8776\n",
            "Epoch 308/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 8.4436e-04 - accuracy: 1.0000 - val_loss: 1.0431 - val_accuracy: 0.8903\n",
            "Epoch 309/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.0888e-04 - accuracy: 1.0000 - val_loss: 0.8551 - val_accuracy: 0.9156\n",
            "Epoch 310/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.0397e-04 - accuracy: 1.0000 - val_loss: 0.7758 - val_accuracy: 0.9241\n",
            "Epoch 311/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 6.6483e-05 - accuracy: 1.0000 - val_loss: 0.7175 - val_accuracy: 0.9283\n",
            "Epoch 312/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.0591e-04 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 0.9283\n",
            "Epoch 313/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.2361e-05 - accuracy: 1.0000 - val_loss: 0.6334 - val_accuracy: 0.9283\n",
            "Epoch 314/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.2020e-05 - accuracy: 1.0000 - val_loss: 0.6020 - val_accuracy: 0.9283\n",
            "Epoch 315/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.5977e-05 - accuracy: 1.0000 - val_loss: 0.5745 - val_accuracy: 0.9325\n",
            "Epoch 316/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.7646e-05 - accuracy: 1.0000 - val_loss: 0.5502 - val_accuracy: 0.9325\n",
            "Epoch 317/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 8.0624e-05 - accuracy: 1.0000 - val_loss: 0.5426 - val_accuracy: 0.9325\n",
            "Epoch 318/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 8.2863e-05 - accuracy: 1.0000 - val_loss: 0.5347 - val_accuracy: 0.9325\n",
            "Epoch 319/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.6012e-04 - accuracy: 1.0000 - val_loss: 0.5273 - val_accuracy: 0.9325\n",
            "Epoch 320/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.8281e-04 - accuracy: 1.0000 - val_loss: 0.5237 - val_accuracy: 0.9325\n",
            "Epoch 321/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.2175e-05 - accuracy: 1.0000 - val_loss: 0.5264 - val_accuracy: 0.9325\n",
            "Epoch 322/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.2634e-04 - accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.9325\n",
            "Epoch 323/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.5081 - val_accuracy: 0.9325\n",
            "Epoch 324/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.1220e-04 - accuracy: 1.0000 - val_loss: 0.5531 - val_accuracy: 0.9283\n",
            "Epoch 325/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.4213e-04 - accuracy: 1.0000 - val_loss: 0.5670 - val_accuracy: 0.9198\n",
            "Epoch 326/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 7.4931e-04 - accuracy: 1.0000 - val_loss: 0.5667 - val_accuracy: 0.9325\n",
            "Epoch 327/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.1254e-04 - accuracy: 1.0000 - val_loss: 0.5648 - val_accuracy: 0.9325\n",
            "Epoch 328/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 9.3776e-05 - accuracy: 1.0000 - val_loss: 0.5563 - val_accuracy: 0.9283\n",
            "Epoch 329/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.5885e-04 - accuracy: 1.0000 - val_loss: 0.5410 - val_accuracy: 0.9283\n",
            "Epoch 330/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.1674e-04 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9451\n",
            "Epoch 331/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.1440e-04 - accuracy: 1.0000 - val_loss: 0.5025 - val_accuracy: 0.9325\n",
            "Epoch 332/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 8.0080e-05 - accuracy: 1.0000 - val_loss: 0.6129 - val_accuracy: 0.9283\n",
            "Epoch 333/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 8.0931e-05 - accuracy: 1.0000 - val_loss: 0.6370 - val_accuracy: 0.9283\n",
            "Epoch 334/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 9.5922e-05 - accuracy: 1.0000 - val_loss: 0.6321 - val_accuracy: 0.9283\n",
            "Epoch 335/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.4227e-05 - accuracy: 1.0000 - val_loss: 0.6302 - val_accuracy: 0.9283\n",
            "Epoch 336/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.9240e-04 - accuracy: 1.0000 - val_loss: 0.6194 - val_accuracy: 0.9283\n",
            "Epoch 337/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 5.8384e-05 - accuracy: 1.0000 - val_loss: 0.6135 - val_accuracy: 0.9283\n",
            "Epoch 338/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 9.2738e-05 - accuracy: 1.0000 - val_loss: 0.5980 - val_accuracy: 0.9325\n",
            "Epoch 339/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.7980e-05 - accuracy: 1.0000 - val_loss: 0.5584 - val_accuracy: 0.9325\n",
            "Epoch 340/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.8671e-04 - accuracy: 1.0000 - val_loss: 0.6243 - val_accuracy: 0.9241\n",
            "Epoch 341/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.1565e-05 - accuracy: 1.0000 - val_loss: 0.6489 - val_accuracy: 0.9156\n",
            "Epoch 342/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.4055e-05 - accuracy: 1.0000 - val_loss: 0.6523 - val_accuracy: 0.9156\n",
            "Epoch 343/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.0588e-05 - accuracy: 1.0000 - val_loss: 0.6536 - val_accuracy: 0.9156\n",
            "Epoch 344/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.0984e-04 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.9198\n",
            "Epoch 345/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.2043e-04 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.9198\n",
            "Epoch 346/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.6050e-05 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.9114\n",
            "Epoch 347/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0020 - accuracy: 0.9978 - val_loss: 0.5878 - val_accuracy: 0.9283\n",
            "Epoch 348/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.9031e-05 - accuracy: 1.0000 - val_loss: 0.5716 - val_accuracy: 0.9325\n",
            "Epoch 349/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.2555e-04 - accuracy: 1.0000 - val_loss: 0.5661 - val_accuracy: 0.9325\n",
            "Epoch 350/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.5865e-05 - accuracy: 1.0000 - val_loss: 0.5711 - val_accuracy: 0.9325\n",
            "Epoch 351/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.0440e-05 - accuracy: 1.0000 - val_loss: 0.5743 - val_accuracy: 0.9325\n",
            "Epoch 352/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.7801e-04 - accuracy: 1.0000 - val_loss: 0.5490 - val_accuracy: 0.9367\n",
            "Epoch 353/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.7434e-05 - accuracy: 1.0000 - val_loss: 0.5463 - val_accuracy: 0.9367\n",
            "Epoch 354/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.1042e-05 - accuracy: 1.0000 - val_loss: 0.5507 - val_accuracy: 0.9367\n",
            "Epoch 355/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.2686e-04 - accuracy: 1.0000 - val_loss: 0.5564 - val_accuracy: 0.9367\n",
            "Epoch 356/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 5.0705e-05 - accuracy: 1.0000 - val_loss: 0.5858 - val_accuracy: 0.9198\n",
            "Epoch 357/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.6840e-04 - accuracy: 1.0000 - val_loss: 0.6372 - val_accuracy: 0.9198\n",
            "Epoch 358/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.6237e-05 - accuracy: 1.0000 - val_loss: 0.6575 - val_accuracy: 0.9198\n",
            "Epoch 359/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 8.5913e-06 - accuracy: 1.0000 - val_loss: 0.6658 - val_accuracy: 0.9198\n",
            "Epoch 360/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.0367e-05 - accuracy: 1.0000 - val_loss: 0.6704 - val_accuracy: 0.9198\n",
            "Epoch 361/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 9.5968e-06 - accuracy: 1.0000 - val_loss: 0.6676 - val_accuracy: 0.9198\n",
            "Epoch 362/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.5834e-06 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.9198\n",
            "Epoch 363/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.0947e-05 - accuracy: 1.0000 - val_loss: 0.6563 - val_accuracy: 0.9198\n",
            "Epoch 364/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.4094e-05 - accuracy: 1.0000 - val_loss: 0.6523 - val_accuracy: 0.9198\n",
            "Epoch 365/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.5314e-04 - accuracy: 1.0000 - val_loss: 0.6495 - val_accuracy: 0.9198\n",
            "Epoch 366/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.4252e-05 - accuracy: 1.0000 - val_loss: 0.6540 - val_accuracy: 0.9283\n",
            "Epoch 367/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.1011e-05 - accuracy: 1.0000 - val_loss: 0.6531 - val_accuracy: 0.9325\n",
            "Epoch 368/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.6722e-04 - accuracy: 1.0000 - val_loss: 0.6596 - val_accuracy: 0.9325\n",
            "Epoch 369/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.5129e-04 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.9367\n",
            "Epoch 370/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.5809e-05 - accuracy: 1.0000 - val_loss: 0.7060 - val_accuracy: 0.9367\n",
            "Epoch 371/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.2823e-05 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.9367\n",
            "Epoch 372/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.7675e-04 - accuracy: 1.0000 - val_loss: 0.7338 - val_accuracy: 0.9325\n",
            "Epoch 373/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.2112e-06 - accuracy: 1.0000 - val_loss: 0.7311 - val_accuracy: 0.9283\n",
            "Epoch 374/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 6.3988e-05 - accuracy: 1.0000 - val_loss: 0.7325 - val_accuracy: 0.9283\n",
            "Epoch 375/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.8134e-06 - accuracy: 1.0000 - val_loss: 0.7315 - val_accuracy: 0.9283\n",
            "Epoch 376/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.9283e-06 - accuracy: 1.0000 - val_loss: 0.7245 - val_accuracy: 0.9283\n",
            "Epoch 377/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 3.0020e-06 - accuracy: 1.0000 - val_loss: 0.7199 - val_accuracy: 0.9283\n",
            "Epoch 378/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 4.6717e-06 - accuracy: 1.0000 - val_loss: 0.7135 - val_accuracy: 0.9283\n",
            "Epoch 379/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 6.0584e-06 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.9283\n",
            "Epoch 380/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.5881e-05 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.9283\n",
            "Epoch 381/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.8936e-06 - accuracy: 1.0000 - val_loss: 0.6910 - val_accuracy: 0.9325\n",
            "Epoch 382/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.8849e-06 - accuracy: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.9325\n",
            "Epoch 383/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.0023e-06 - accuracy: 1.0000 - val_loss: 0.6824 - val_accuracy: 0.9325\n",
            "Epoch 384/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.9316e-06 - accuracy: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.9325\n",
            "Epoch 385/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.2355e-04 - accuracy: 1.0000 - val_loss: 0.6484 - val_accuracy: 0.9325\n",
            "Epoch 386/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 6.6041e-06 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 0.9367\n",
            "Epoch 387/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.0598e-05 - accuracy: 1.0000 - val_loss: 0.6106 - val_accuracy: 0.9367\n",
            "Epoch 388/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.4802e-06 - accuracy: 1.0000 - val_loss: 0.5662 - val_accuracy: 0.9325\n",
            "Epoch 389/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 8.9972e-06 - accuracy: 1.0000 - val_loss: 0.5630 - val_accuracy: 0.9325\n",
            "Epoch 390/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.8924e-06 - accuracy: 1.0000 - val_loss: 0.5627 - val_accuracy: 0.9325\n",
            "Epoch 391/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 1.0204e-05 - accuracy: 1.0000 - val_loss: 0.5635 - val_accuracy: 0.9325\n",
            "Epoch 392/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.4249e-05 - accuracy: 1.0000 - val_loss: 0.5686 - val_accuracy: 0.9325\n",
            "Epoch 393/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 3.0100e-06 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.9409\n",
            "Epoch 394/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.0650e-05 - accuracy: 1.0000 - val_loss: 0.5798 - val_accuracy: 0.9367\n",
            "Epoch 395/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 7.2682e-06 - accuracy: 1.0000 - val_loss: 0.5823 - val_accuracy: 0.9325\n",
            "Epoch 396/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.1867e-06 - accuracy: 1.0000 - val_loss: 0.5836 - val_accuracy: 0.9325\n",
            "Epoch 397/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.2890e-05 - accuracy: 1.0000 - val_loss: 0.5854 - val_accuracy: 0.9325\n",
            "Epoch 398/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.1156e-06 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.9325\n",
            "Epoch 399/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 4.3621e-06 - accuracy: 1.0000 - val_loss: 0.5902 - val_accuracy: 0.9325\n",
            "Epoch 400/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.7109e-06 - accuracy: 1.0000 - val_loss: 0.5922 - val_accuracy: 0.9325\n",
            "Epoch 401/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.1528e-06 - accuracy: 1.0000 - val_loss: 0.5939 - val_accuracy: 0.9325\n",
            "Epoch 402/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 2.6439e-06 - accuracy: 1.0000 - val_loss: 0.5963 - val_accuracy: 0.9325\n",
            "Epoch 403/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.6799e-06 - accuracy: 1.0000 - val_loss: 0.5971 - val_accuracy: 0.9325\n",
            "Epoch 404/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 4.8151e-06 - accuracy: 1.0000 - val_loss: 0.5985 - val_accuracy: 0.9325\n",
            "Epoch 405/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.4942e-06 - accuracy: 1.0000 - val_loss: 0.5987 - val_accuracy: 0.9325\n",
            "Epoch 406/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.0338e-05 - accuracy: 1.0000 - val_loss: 0.6031 - val_accuracy: 0.9325\n",
            "Epoch 407/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.1512e-06 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.9325\n",
            "Epoch 408/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.8726e-06 - accuracy: 1.0000 - val_loss: 0.6085 - val_accuracy: 0.9367\n",
            "Epoch 409/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.7301e-06 - accuracy: 1.0000 - val_loss: 0.6097 - val_accuracy: 0.9367\n",
            "Epoch 410/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.8573e-06 - accuracy: 1.0000 - val_loss: 0.6112 - val_accuracy: 0.9367\n",
            "Epoch 411/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.2184e-06 - accuracy: 1.0000 - val_loss: 0.6117 - val_accuracy: 0.9367\n",
            "Epoch 412/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.4413e-06 - accuracy: 1.0000 - val_loss: 0.6159 - val_accuracy: 0.9367\n",
            "Epoch 413/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.1368e-06 - accuracy: 1.0000 - val_loss: 0.6179 - val_accuracy: 0.9367\n",
            "Epoch 414/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.4427e-06 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.9367\n",
            "Epoch 415/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.3226e-06 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.9367\n",
            "Epoch 416/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.3423e-05 - accuracy: 1.0000 - val_loss: 0.6221 - val_accuracy: 0.9367\n",
            "Epoch 417/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 1.4966e-06 - accuracy: 1.0000 - val_loss: 0.6216 - val_accuracy: 0.9367\n",
            "Epoch 418/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.0136e-05 - accuracy: 1.0000 - val_loss: 0.6243 - val_accuracy: 0.9367\n",
            "Epoch 419/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.6703e-06 - accuracy: 1.0000 - val_loss: 0.6233 - val_accuracy: 0.9367\n",
            "Epoch 420/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.1186e-06 - accuracy: 1.0000 - val_loss: 0.6244 - val_accuracy: 0.9367\n",
            "Epoch 421/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.1282e-05 - accuracy: 1.0000 - val_loss: 0.6281 - val_accuracy: 0.9367\n",
            "Epoch 422/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.0745e-06 - accuracy: 1.0000 - val_loss: 0.6328 - val_accuracy: 0.9367\n",
            "Epoch 423/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.3156e-06 - accuracy: 1.0000 - val_loss: 0.6346 - val_accuracy: 0.9325\n",
            "Epoch 424/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.8981e-06 - accuracy: 1.0000 - val_loss: 0.6353 - val_accuracy: 0.9325\n",
            "Epoch 425/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 9.2746e-06 - accuracy: 1.0000 - val_loss: 0.6390 - val_accuracy: 0.9325\n",
            "Epoch 426/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.8395e-06 - accuracy: 1.0000 - val_loss: 0.6417 - val_accuracy: 0.9325\n",
            "Epoch 427/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.1090e-05 - accuracy: 1.0000 - val_loss: 0.6480 - val_accuracy: 0.9325\n",
            "Epoch 428/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.2437e-06 - accuracy: 1.0000 - val_loss: 0.6492 - val_accuracy: 0.9325\n",
            "Epoch 429/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 5.8468e-05 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.9367\n",
            "Epoch 430/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.8257e-06 - accuracy: 1.0000 - val_loss: 0.7143 - val_accuracy: 0.9409\n",
            "Epoch 431/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.4237e-06 - accuracy: 1.0000 - val_loss: 0.7217 - val_accuracy: 0.9409\n",
            "Epoch 432/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.7077e-06 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.9409\n",
            "Epoch 433/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.3976e-06 - accuracy: 1.0000 - val_loss: 0.7259 - val_accuracy: 0.9409\n",
            "Epoch 434/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.3513e-06 - accuracy: 1.0000 - val_loss: 0.7261 - val_accuracy: 0.9409\n",
            "Epoch 435/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.5764e-05 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.9409\n",
            "Epoch 436/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.5849e-06 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.9325\n",
            "Epoch 437/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.3079e-06 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.9325\n",
            "Epoch 438/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 6.1170e-06 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.9325\n",
            "Epoch 439/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.8098e-06 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.9367\n",
            "Epoch 440/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.1116e-06 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.9367\n",
            "Epoch 441/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.3129e-06 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.9367\n",
            "Epoch 442/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.4683e-06 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.9325\n",
            "Epoch 443/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.0191e-06 - accuracy: 1.0000 - val_loss: 0.7113 - val_accuracy: 0.9325\n",
            "Epoch 444/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.6366e-06 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.9367\n",
            "Epoch 445/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.5426e-06 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.9367\n",
            "Epoch 446/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.3034e-06 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.9367\n",
            "Epoch 447/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.5648e-06 - accuracy: 1.0000 - val_loss: 0.7101 - val_accuracy: 0.9367\n",
            "Epoch 448/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.4980e-06 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.9367\n",
            "Epoch 449/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.2870e-06 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.9367\n",
            "Epoch 450/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.0254e-06 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.9367\n",
            "Epoch 451/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.1072e-06 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.9367\n",
            "Epoch 452/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.5125e-06 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.9367\n",
            "Epoch 453/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.9547e-05 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.9367\n",
            "Epoch 454/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.0747e-06 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.9367\n",
            "Epoch 455/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 8.7169e-06 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.9367\n",
            "Epoch 456/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.3059e-05 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.9367\n",
            "Epoch 457/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 8.0998e-07 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.9325\n",
            "Epoch 458/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.4972e-06 - accuracy: 1.0000 - val_loss: 0.7084 - val_accuracy: 0.9325\n",
            "Epoch 459/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.0244e-06 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.9283\n",
            "Epoch 460/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 5.7830e-07 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.9283\n",
            "Epoch 461/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 8.3009e-07 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.9283\n",
            "Epoch 462/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.0504e-06 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.9325\n",
            "Epoch 463/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.5605e-06 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.9325\n",
            "Epoch 464/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.6191e-05 - accuracy: 1.0000 - val_loss: 0.7031 - val_accuracy: 0.9325\n",
            "Epoch 465/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.9194e-06 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.9325\n",
            "Epoch 466/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.8629e-07 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.9325\n",
            "Epoch 467/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 7.2021e-07 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.9367\n",
            "Epoch 468/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.0560e-06 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.9367\n",
            "Epoch 469/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.6076e-06 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.9367\n",
            "Epoch 470/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.1324e-06 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.9367\n",
            "Epoch 471/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 8.5022e-06 - accuracy: 1.0000 - val_loss: 0.7065 - val_accuracy: 0.9325\n",
            "Epoch 472/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.1586e-06 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.9367\n",
            "Epoch 473/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 5.7207e-07 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.9367\n",
            "Epoch 474/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.7616e-06 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.9325\n",
            "Epoch 475/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 9.9198e-07 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.9325\n",
            "Epoch 476/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.8731e-06 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.9325\n",
            "Epoch 477/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 6.4304e-07 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.9325\n",
            "Epoch 478/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.0259e-07 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.9325\n",
            "Epoch 479/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.9577e-06 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.9325\n",
            "Epoch 480/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 5.7164e-07 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.9325\n",
            "Epoch 481/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.9353e-05 - accuracy: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.9367\n",
            "Epoch 482/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 8.0217e-07 - accuracy: 1.0000 - val_loss: 0.6864 - val_accuracy: 0.9325\n",
            "Epoch 483/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.6175e-06 - accuracy: 1.0000 - val_loss: 0.6864 - val_accuracy: 0.9325\n",
            "Epoch 484/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.9464e-07 - accuracy: 1.0000 - val_loss: 0.6899 - val_accuracy: 0.9325\n",
            "Epoch 485/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 4.5489e-06 - accuracy: 1.0000 - val_loss: 0.6928 - val_accuracy: 0.9283\n",
            "Epoch 486/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 8.0150e-07 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.9283\n",
            "Epoch 487/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.3139e-06 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.9283\n",
            "Epoch 488/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.0113e-06 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.9283\n",
            "Epoch 489/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.3946e-06 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.9283\n",
            "Epoch 490/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.8692e-06 - accuracy: 1.0000 - val_loss: 0.7065 - val_accuracy: 0.9283\n",
            "Epoch 491/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 9.0115e-07 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.9283\n",
            "Epoch 492/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.1665e-06 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.9283\n",
            "Epoch 493/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.3606e-07 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.9283\n",
            "Epoch 494/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 7.6925e-06 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.9283\n",
            "Epoch 495/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.6384e-06 - accuracy: 1.0000 - val_loss: 0.7425 - val_accuracy: 0.9325\n",
            "Epoch 496/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.1625e-07 - accuracy: 1.0000 - val_loss: 0.7477 - val_accuracy: 0.9325\n",
            "Epoch 497/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 8.3094e-06 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 0.9325\n",
            "Epoch 498/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.0981e-06 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.9367\n",
            "Epoch 499/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.2801e-07 - accuracy: 1.0000 - val_loss: 0.7513 - val_accuracy: 0.9367\n",
            "Epoch 500/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.5615e-06 - accuracy: 1.0000 - val_loss: 0.7502 - val_accuracy: 0.9367\n",
            "Epoch 501/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 7.7794e-07 - accuracy: 1.0000 - val_loss: 0.7492 - val_accuracy: 0.9367\n",
            "Epoch 502/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.3996e-07 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.9367\n",
            "Epoch 503/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.6521e-07 - accuracy: 1.0000 - val_loss: 0.7462 - val_accuracy: 0.9367\n",
            "Epoch 504/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.6905e-07 - accuracy: 1.0000 - val_loss: 0.7461 - val_accuracy: 0.9367\n",
            "Epoch 505/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 8.4365e-07 - accuracy: 1.0000 - val_loss: 0.7460 - val_accuracy: 0.9367\n",
            "Epoch 506/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.7146e-05 - accuracy: 1.0000 - val_loss: 0.7543 - val_accuracy: 0.9367\n",
            "Epoch 507/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.6895e-06 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.9367\n",
            "Epoch 508/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.8838e-06 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.9367\n",
            "Epoch 509/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 8.3266e-07 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.9367\n",
            "Epoch 510/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 3.5660e-06 - accuracy: 1.0000 - val_loss: 0.7581 - val_accuracy: 0.9367\n",
            "Epoch 511/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.0829e-07 - accuracy: 1.0000 - val_loss: 0.7608 - val_accuracy: 0.9367\n",
            "Epoch 512/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.7781e-05 - accuracy: 1.0000 - val_loss: 0.7642 - val_accuracy: 0.9367\n",
            "Epoch 513/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.0855e-05 - accuracy: 1.0000 - val_loss: 0.7795 - val_accuracy: 0.9409\n",
            "Epoch 514/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.1194e-06 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.9325\n",
            "Epoch 515/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.2361e-06 - accuracy: 1.0000 - val_loss: 0.8071 - val_accuracy: 0.9325\n",
            "Epoch 516/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.0309e-06 - accuracy: 1.0000 - val_loss: 0.8093 - val_accuracy: 0.9325\n",
            "Epoch 517/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 8.4516e-07 - accuracy: 1.0000 - val_loss: 0.8091 - val_accuracy: 0.9325\n",
            "Epoch 518/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 9.8560e-07 - accuracy: 1.0000 - val_loss: 0.8101 - val_accuracy: 0.9367\n",
            "Epoch 519/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 4.7842e-06 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.9367\n",
            "Epoch 520/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 9.9936e-05 - accuracy: 1.0000 - val_loss: 0.8403 - val_accuracy: 0.9409\n",
            "Epoch 521/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 4.1644e-05 - accuracy: 1.0000 - val_loss: 0.9064 - val_accuracy: 0.9198\n",
            "Epoch 522/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 8.4460e-07 - accuracy: 1.0000 - val_loss: 0.9347 - val_accuracy: 0.9241\n",
            "Epoch 523/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.0678e-06 - accuracy: 1.0000 - val_loss: 0.9208 - val_accuracy: 0.9241\n",
            "Epoch 524/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.8584e-06 - accuracy: 1.0000 - val_loss: 0.9055 - val_accuracy: 0.9241\n",
            "Epoch 525/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.7289e-06 - accuracy: 1.0000 - val_loss: 0.8898 - val_accuracy: 0.9283\n",
            "Epoch 526/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.2457e-05 - accuracy: 1.0000 - val_loss: 0.8735 - val_accuracy: 0.9283\n",
            "Epoch 527/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.0059e-06 - accuracy: 1.0000 - val_loss: 0.8599 - val_accuracy: 0.9283\n",
            "Epoch 528/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 5.0432e-06 - accuracy: 1.0000 - val_loss: 0.8473 - val_accuracy: 0.9283\n",
            "Epoch 529/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.0783e-06 - accuracy: 1.0000 - val_loss: 0.8354 - val_accuracy: 0.9283\n",
            "Epoch 530/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.3031e-05 - accuracy: 1.0000 - val_loss: 0.8247 - val_accuracy: 0.9283\n",
            "Epoch 531/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.0668e-06 - accuracy: 1.0000 - val_loss: 0.8169 - val_accuracy: 0.9283\n",
            "Epoch 532/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.6990e-06 - accuracy: 1.0000 - val_loss: 0.8082 - val_accuracy: 0.9283\n",
            "Epoch 533/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.0137e-06 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.9283\n",
            "Epoch 534/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.4365e-06 - accuracy: 1.0000 - val_loss: 0.7972 - val_accuracy: 0.9283\n",
            "Epoch 535/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.8095e-06 - accuracy: 1.0000 - val_loss: 0.7909 - val_accuracy: 0.9325\n",
            "Epoch 536/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.4597e-06 - accuracy: 1.0000 - val_loss: 0.7898 - val_accuracy: 0.9283\n",
            "Epoch 537/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.1848e-06 - accuracy: 1.0000 - val_loss: 0.7837 - val_accuracy: 0.9367\n",
            "Epoch 538/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.3694e-06 - accuracy: 1.0000 - val_loss: 0.7826 - val_accuracy: 0.9367\n",
            "Epoch 539/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.8229e-06 - accuracy: 1.0000 - val_loss: 0.7804 - val_accuracy: 0.9367\n",
            "Epoch 540/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 5.3347e-06 - accuracy: 1.0000 - val_loss: 0.7777 - val_accuracy: 0.9367\n",
            "Epoch 541/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.2360e-06 - accuracy: 1.0000 - val_loss: 0.7772 - val_accuracy: 0.9367\n",
            "Epoch 542/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 5.2209e-07 - accuracy: 1.0000 - val_loss: 0.7770 - val_accuracy: 0.9367\n",
            "Epoch 543/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.1232e-06 - accuracy: 1.0000 - val_loss: 0.7793 - val_accuracy: 0.9367\n",
            "Epoch 544/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 6.2779e-07 - accuracy: 1.0000 - val_loss: 0.7781 - val_accuracy: 0.9325\n",
            "Epoch 545/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.7113e-06 - accuracy: 1.0000 - val_loss: 0.7785 - val_accuracy: 0.9367\n",
            "Epoch 546/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.9444e-06 - accuracy: 1.0000 - val_loss: 0.7772 - val_accuracy: 0.9325\n",
            "Epoch 547/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.6744e-07 - accuracy: 1.0000 - val_loss: 0.7759 - val_accuracy: 0.9325\n",
            "Epoch 548/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.0106e-04 - accuracy: 1.0000 - val_loss: 0.6649 - val_accuracy: 0.9283\n",
            "Epoch 549/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 9.4728e-06 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 0.9325\n",
            "Epoch 550/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 5.7020e-07 - accuracy: 1.0000 - val_loss: 0.6625 - val_accuracy: 0.9325\n",
            "Epoch 551/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 5.1644e-07 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 0.9283\n",
            "Epoch 552/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 9.2948e-07 - accuracy: 1.0000 - val_loss: 0.6620 - val_accuracy: 0.9325\n",
            "Epoch 553/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.4296e-06 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.9367\n",
            "Epoch 554/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.4557e-05 - accuracy: 1.0000 - val_loss: 0.6683 - val_accuracy: 0.9367\n",
            "Epoch 555/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.1420e-07 - accuracy: 1.0000 - val_loss: 0.7396 - val_accuracy: 0.9325\n",
            "Epoch 556/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.3741e-06 - accuracy: 1.0000 - val_loss: 0.7638 - val_accuracy: 0.9325\n",
            "Epoch 557/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.8011e-06 - accuracy: 1.0000 - val_loss: 0.7726 - val_accuracy: 0.9325\n",
            "Epoch 558/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.5331e-06 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.9325\n",
            "Epoch 559/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.5663e-07 - accuracy: 1.0000 - val_loss: 0.7775 - val_accuracy: 0.9325\n",
            "Epoch 560/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.2868e-06 - accuracy: 1.0000 - val_loss: 0.7786 - val_accuracy: 0.9325\n",
            "Epoch 561/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 9.7065e-07 - accuracy: 1.0000 - val_loss: 0.7783 - val_accuracy: 0.9325\n",
            "Epoch 562/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.8073e-07 - accuracy: 1.0000 - val_loss: 0.7781 - val_accuracy: 0.9325\n",
            "Epoch 563/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.3493e-07 - accuracy: 1.0000 - val_loss: 0.7784 - val_accuracy: 0.9325\n",
            "Epoch 564/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.1640e-06 - accuracy: 1.0000 - val_loss: 0.7792 - val_accuracy: 0.9325\n",
            "Epoch 565/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.9060e-07 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.9367\n",
            "Epoch 566/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.6055e-07 - accuracy: 1.0000 - val_loss: 0.7822 - val_accuracy: 0.9325\n",
            "Epoch 567/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 3.6430e-07 - accuracy: 1.0000 - val_loss: 0.7826 - val_accuracy: 0.9325\n",
            "Epoch 568/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 9.6295e-08 - accuracy: 1.0000 - val_loss: 0.7827 - val_accuracy: 0.9325\n",
            "Epoch 569/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 1.3561e-06 - accuracy: 1.0000 - val_loss: 0.7846 - val_accuracy: 0.9367\n",
            "Epoch 570/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 4.7825e-07 - accuracy: 1.0000 - val_loss: 0.7870 - val_accuracy: 0.9367\n",
            "Epoch 571/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.1245e-06 - accuracy: 1.0000 - val_loss: 0.7863 - val_accuracy: 0.9325\n",
            "Epoch 572/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 6.2007e-06 - accuracy: 1.0000 - val_loss: 0.7917 - val_accuracy: 0.9367\n",
            "Epoch 573/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.7011e-07 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.9367\n",
            "Epoch 574/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.0175e-06 - accuracy: 1.0000 - val_loss: 0.7974 - val_accuracy: 0.9367\n",
            "Epoch 575/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.0017e-07 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.9367\n",
            "Epoch 576/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.2430e-06 - accuracy: 1.0000 - val_loss: 0.7968 - val_accuracy: 0.9367\n",
            "Epoch 577/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.5406e-06 - accuracy: 1.0000 - val_loss: 0.7980 - val_accuracy: 0.9367\n",
            "Epoch 578/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 4.6887e-06 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.9367\n",
            "Epoch 579/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 4.5922e-07 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.9367\n",
            "Epoch 580/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.0900e-06 - accuracy: 1.0000 - val_loss: 0.8012 - val_accuracy: 0.9367\n",
            "Epoch 581/1000\n",
            "13/13 [==============================] - 3s 228ms/step - loss: 1.3652e-06 - accuracy: 1.0000 - val_loss: 0.8007 - val_accuracy: 0.9367\n",
            "Epoch 582/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 1.2135e-07 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.9367\n",
            "Epoch 583/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.9589e-07 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.9367\n",
            "Epoch 584/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 5.4401e-07 - accuracy: 1.0000 - val_loss: 0.7995 - val_accuracy: 0.9367\n",
            "Epoch 585/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.2932e-07 - accuracy: 1.0000 - val_loss: 0.7987 - val_accuracy: 0.9367\n",
            "Epoch 586/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.7141e-07 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.9367\n",
            "Epoch 587/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.4287e-06 - accuracy: 1.0000 - val_loss: 0.7997 - val_accuracy: 0.9367\n",
            "Epoch 588/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.9483e-07 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.9367\n",
            "Epoch 589/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.3502e-07 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.9367\n",
            "Epoch 590/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.6466e-06 - accuracy: 1.0000 - val_loss: 0.7987 - val_accuracy: 0.9367\n",
            "Epoch 591/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 4.4770e-07 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.9325\n",
            "Epoch 592/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.6655e-07 - accuracy: 1.0000 - val_loss: 0.7967 - val_accuracy: 0.9325\n",
            "Epoch 593/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.0117e-07 - accuracy: 1.0000 - val_loss: 0.7973 - val_accuracy: 0.9325\n",
            "Epoch 594/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 6.2026e-07 - accuracy: 1.0000 - val_loss: 0.7974 - val_accuracy: 0.9325\n",
            "Epoch 595/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.1672e-07 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.9325\n",
            "Epoch 596/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.0029e-06 - accuracy: 1.0000 - val_loss: 0.7989 - val_accuracy: 0.9367\n",
            "Epoch 597/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.7192e-07 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.9325\n",
            "Epoch 598/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 3.8992e-07 - accuracy: 1.0000 - val_loss: 0.7989 - val_accuracy: 0.9325\n",
            "Epoch 599/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 8.2826e-07 - accuracy: 1.0000 - val_loss: 0.7979 - val_accuracy: 0.9325\n",
            "Epoch 600/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.8794 - val_accuracy: 0.9325\n",
            "Epoch 601/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0233 - accuracy: 0.9950 - val_loss: 3.7821 - val_accuracy: 0.7806\n",
            "Epoch 602/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0424 - accuracy: 0.9851 - val_loss: 0.7414 - val_accuracy: 0.8945\n",
            "Epoch 603/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0215 - accuracy: 0.9969 - val_loss: 10.1522 - val_accuracy: 0.5274\n",
            "Epoch 604/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0366 - accuracy: 0.9964 - val_loss: 1.8171 - val_accuracy: 0.8650\n",
            "Epoch 605/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0555 - accuracy: 0.9838 - val_loss: 0.8005 - val_accuracy: 0.8439\n",
            "Epoch 606/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0178 - accuracy: 0.9907 - val_loss: 1.0031 - val_accuracy: 0.8270\n",
            "Epoch 607/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0178 - accuracy: 0.9910 - val_loss: 2.4523 - val_accuracy: 0.6751\n",
            "Epoch 608/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0136 - accuracy: 0.9942 - val_loss: 5.2610 - val_accuracy: 0.5232\n",
            "Epoch 609/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0284 - accuracy: 0.9875 - val_loss: 0.9991 - val_accuracy: 0.8565\n",
            "Epoch 610/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 1.1642 - val_accuracy: 0.8819\n",
            "Epoch 611/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0110 - accuracy: 0.9990 - val_loss: 2.5190 - val_accuracy: 0.8143\n",
            "Epoch 612/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 4.0301 - val_accuracy: 0.7468\n",
            "Epoch 613/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.9386e-04 - accuracy: 1.0000 - val_loss: 3.7073 - val_accuracy: 0.7468\n",
            "Epoch 614/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0354 - accuracy: 0.9916 - val_loss: 1.7741 - val_accuracy: 0.8143\n",
            "Epoch 615/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 7.7161 - val_accuracy: 0.5865\n",
            "Epoch 616/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0214 - accuracy: 0.9957 - val_loss: 0.9942 - val_accuracy: 0.8059\n",
            "Epoch 617/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0350 - accuracy: 0.9862 - val_loss: 0.6725 - val_accuracy: 0.8608\n",
            "Epoch 618/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.7313 - val_accuracy: 0.8734\n",
            "Epoch 619/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.6754 - val_accuracy: 0.8776\n",
            "Epoch 620/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.8903\n",
            "Epoch 621/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.1614e-04 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.8987\n",
            "Epoch 622/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.2799e-04 - accuracy: 1.0000 - val_loss: 0.6827 - val_accuracy: 0.9030\n",
            "Epoch 623/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.9572e-04 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.9030\n",
            "Epoch 624/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 9.3383e-05 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.9030\n",
            "Epoch 625/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.1451e-04 - accuracy: 1.0000 - val_loss: 0.7326 - val_accuracy: 0.9072\n",
            "Epoch 626/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.9450e-04 - accuracy: 1.0000 - val_loss: 0.7592 - val_accuracy: 0.9072\n",
            "Epoch 627/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.7694e-04 - accuracy: 1.0000 - val_loss: 0.7736 - val_accuracy: 0.9114\n",
            "Epoch 628/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.2221e-05 - accuracy: 1.0000 - val_loss: 0.7811 - val_accuracy: 0.9114\n",
            "Epoch 629/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0377 - accuracy: 0.9978 - val_loss: 0.7149 - val_accuracy: 0.9156\n",
            "Epoch 630/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0070 - accuracy: 0.9958 - val_loss: 0.7111 - val_accuracy: 0.9114\n",
            "Epoch 631/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8074 - val_accuracy: 0.9072\n",
            "Epoch 632/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.3232e-04 - accuracy: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.9030\n",
            "Epoch 633/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.8571e-04 - accuracy: 1.0000 - val_loss: 0.6730 - val_accuracy: 0.9198\n",
            "Epoch 634/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.0684e-04 - accuracy: 1.0000 - val_loss: 0.6569 - val_accuracy: 0.9198\n",
            "Epoch 635/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.6068e-04 - accuracy: 1.0000 - val_loss: 0.6591 - val_accuracy: 0.9114\n",
            "Epoch 636/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.0359e-04 - accuracy: 1.0000 - val_loss: 0.6719 - val_accuracy: 0.9114\n",
            "Epoch 637/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.5352e-04 - accuracy: 1.0000 - val_loss: 0.6903 - val_accuracy: 0.9114\n",
            "Epoch 638/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 2.7221e-05 - accuracy: 1.0000 - val_loss: 0.6989 - val_accuracy: 0.9114\n",
            "Epoch 639/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 4.9988e-05 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.9156\n",
            "Epoch 640/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.8519e-05 - accuracy: 1.0000 - val_loss: 0.6987 - val_accuracy: 0.9156\n",
            "Epoch 641/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.2811e-05 - accuracy: 1.0000 - val_loss: 0.6973 - val_accuracy: 0.9198\n",
            "Epoch 642/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.1906e-04 - accuracy: 0.9998 - val_loss: 0.6929 - val_accuracy: 0.9156\n",
            "Epoch 643/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.6496 - val_accuracy: 0.9198\n",
            "Epoch 644/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 7.7591e-04 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.9114\n",
            "Epoch 645/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.4505e-04 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.9072\n",
            "Epoch 646/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 1.2335 - val_accuracy: 0.8734\n",
            "Epoch 647/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.7740e-04 - accuracy: 1.0000 - val_loss: 1.5252 - val_accuracy: 0.8565\n",
            "Epoch 648/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0244 - accuracy: 0.9971 - val_loss: 0.8217 - val_accuracy: 0.9030\n",
            "Epoch 649/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.1284e-04 - accuracy: 1.0000 - val_loss: 0.7466 - val_accuracy: 0.9114\n",
            "Epoch 650/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.7026e-04 - accuracy: 1.0000 - val_loss: 0.7304 - val_accuracy: 0.9114\n",
            "Epoch 651/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7227 - val_accuracy: 0.9156\n",
            "Epoch 652/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 0.0012 - accuracy: 0.9991 - val_loss: 0.7121 - val_accuracy: 0.9325\n",
            "Epoch 653/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7725 - val_accuracy: 0.9283\n",
            "Epoch 654/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 4.9882e-04 - accuracy: 1.0000 - val_loss: 0.8364 - val_accuracy: 0.9072\n",
            "Epoch 655/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 0.9049 - val_accuracy: 0.9030\n",
            "Epoch 656/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.0550e-05 - accuracy: 1.0000 - val_loss: 0.8952 - val_accuracy: 0.8987\n",
            "Epoch 657/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 5.6549e-05 - accuracy: 1.0000 - val_loss: 0.8543 - val_accuracy: 0.8987\n",
            "Epoch 658/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.5438e-05 - accuracy: 1.0000 - val_loss: 0.8169 - val_accuracy: 0.8987\n",
            "Epoch 659/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.7173e-05 - accuracy: 1.0000 - val_loss: 0.7881 - val_accuracy: 0.8987\n",
            "Epoch 660/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7605 - val_accuracy: 0.9072\n",
            "Epoch 661/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.7031e-05 - accuracy: 1.0000 - val_loss: 0.7600 - val_accuracy: 0.9114\n",
            "Epoch 662/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.4496e-04 - accuracy: 1.0000 - val_loss: 0.7441 - val_accuracy: 0.9156\n",
            "Epoch 663/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.7019e-05 - accuracy: 1.0000 - val_loss: 0.7393 - val_accuracy: 0.9072\n",
            "Epoch 664/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.2117e-05 - accuracy: 1.0000 - val_loss: 0.7426 - val_accuracy: 0.9114\n",
            "Epoch 665/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 6.2947e-05 - accuracy: 1.0000 - val_loss: 0.7453 - val_accuracy: 0.9114\n",
            "Epoch 666/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 9.4859e-06 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.9156\n",
            "Epoch 667/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 6.4138e-06 - accuracy: 1.0000 - val_loss: 0.7595 - val_accuracy: 0.9156\n",
            "Epoch 668/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.2151e-06 - accuracy: 1.0000 - val_loss: 0.7638 - val_accuracy: 0.9156\n",
            "Epoch 669/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.1751e-06 - accuracy: 1.0000 - val_loss: 0.7669 - val_accuracy: 0.9156\n",
            "Epoch 670/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 4.7585e-05 - accuracy: 1.0000 - val_loss: 0.7696 - val_accuracy: 0.9198\n",
            "Epoch 671/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.1273e-05 - accuracy: 1.0000 - val_loss: 0.7725 - val_accuracy: 0.9198\n",
            "Epoch 672/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.2056e-05 - accuracy: 1.0000 - val_loss: 0.7767 - val_accuracy: 0.9156\n",
            "Epoch 673/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.1766e-05 - accuracy: 1.0000 - val_loss: 0.7797 - val_accuracy: 0.9156\n",
            "Epoch 674/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.4530e-05 - accuracy: 1.0000 - val_loss: 0.7818 - val_accuracy: 0.9156\n",
            "Epoch 675/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.7388e-05 - accuracy: 1.0000 - val_loss: 0.7840 - val_accuracy: 0.9156\n",
            "Epoch 676/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 7.8708e-06 - accuracy: 1.0000 - val_loss: 0.7852 - val_accuracy: 0.9156\n",
            "Epoch 677/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 5.5979e-06 - accuracy: 1.0000 - val_loss: 0.7867 - val_accuracy: 0.9156\n",
            "Epoch 678/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0255 - accuracy: 0.9957 - val_loss: 5.3800 - val_accuracy: 0.5401\n",
            "Epoch 679/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 4.2610 - val_accuracy: 0.5992\n",
            "Epoch 680/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 6.9866 - val_accuracy: 0.4515\n",
            "Epoch 681/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0189 - accuracy: 0.9985 - val_loss: 4.2738 - val_accuracy: 0.5274\n",
            "Epoch 682/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9800 - val_accuracy: 0.7300\n",
            "Epoch 683/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0257 - accuracy: 0.9964 - val_loss: 1.1076 - val_accuracy: 0.8270\n",
            "Epoch 684/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.8734\n",
            "Epoch 685/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 6.9336e-04 - accuracy: 1.0000 - val_loss: 0.6609 - val_accuracy: 0.8987\n",
            "Epoch 686/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.0395e-04 - accuracy: 0.9998 - val_loss: 0.6620 - val_accuracy: 0.9072\n",
            "Epoch 687/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.2881e-04 - accuracy: 1.0000 - val_loss: 1.0219 - val_accuracy: 0.8734\n",
            "Epoch 688/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9911 - val_accuracy: 0.8734\n",
            "Epoch 689/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 9.2667e-04 - accuracy: 1.0000 - val_loss: 0.8974 - val_accuracy: 0.8819\n",
            "Epoch 690/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0242 - accuracy: 0.9913 - val_loss: 0.7613 - val_accuracy: 0.8987\n",
            "Epoch 691/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0027 - accuracy: 0.9981 - val_loss: 0.9185 - val_accuracy: 0.8987\n",
            "Epoch 692/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.5822e-04 - accuracy: 1.0000 - val_loss: 1.0918 - val_accuracy: 0.8903\n",
            "Epoch 693/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.2171e-05 - accuracy: 1.0000 - val_loss: 1.0813 - val_accuracy: 0.8903\n",
            "Epoch 694/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 2.8540e-05 - accuracy: 1.0000 - val_loss: 1.0283 - val_accuracy: 0.8987\n",
            "Epoch 695/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.9350e-05 - accuracy: 1.0000 - val_loss: 0.9965 - val_accuracy: 0.9030\n",
            "Epoch 696/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.9280e-05 - accuracy: 1.0000 - val_loss: 0.9788 - val_accuracy: 0.9030\n",
            "Epoch 697/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.6585e-05 - accuracy: 1.0000 - val_loss: 0.9582 - val_accuracy: 0.9072\n",
            "Epoch 698/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.5221e-05 - accuracy: 1.0000 - val_loss: 0.9403 - val_accuracy: 0.9072\n",
            "Epoch 699/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.7258e-05 - accuracy: 1.0000 - val_loss: 0.9334 - val_accuracy: 0.9072\n",
            "Epoch 700/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.0424e-05 - accuracy: 1.0000 - val_loss: 0.9265 - val_accuracy: 0.9072\n",
            "Epoch 701/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 0.8373 - val_accuracy: 0.9114\n",
            "Epoch 702/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.5205e-04 - accuracy: 1.0000 - val_loss: 0.8081 - val_accuracy: 0.9072\n",
            "Epoch 703/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.0271e-04 - accuracy: 1.0000 - val_loss: 0.8012 - val_accuracy: 0.9072\n",
            "Epoch 704/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.1015e-04 - accuracy: 0.9997 - val_loss: 0.7774 - val_accuracy: 0.9072\n",
            "Epoch 705/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.9198\n",
            "Epoch 706/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.1807e-04 - accuracy: 1.0000 - val_loss: 0.7814 - val_accuracy: 0.9156\n",
            "Epoch 707/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.3972e-05 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.9198\n",
            "Epoch 708/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.8814e-05 - accuracy: 1.0000 - val_loss: 0.7660 - val_accuracy: 0.9198\n",
            "Epoch 709/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.1037e-04 - accuracy: 1.0000 - val_loss: 0.7709 - val_accuracy: 0.9156\n",
            "Epoch 710/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.9042e-05 - accuracy: 1.0000 - val_loss: 0.7833 - val_accuracy: 0.9241\n",
            "Epoch 711/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.7437e-05 - accuracy: 1.0000 - val_loss: 0.7934 - val_accuracy: 0.9198\n",
            "Epoch 712/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0010 - accuracy: 0.9993 - val_loss: 0.8017 - val_accuracy: 0.9156\n",
            "Epoch 713/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.9075 - val_accuracy: 0.9114\n",
            "Epoch 714/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0159 - accuracy: 0.9979 - val_loss: 0.6968 - val_accuracy: 0.9156\n",
            "Epoch 715/1000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 1.0539 - val_accuracy: 0.8692\n",
            "Epoch 716/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0161 - accuracy: 0.9968 - val_loss: 0.9603 - val_accuracy: 0.8819\n",
            "Epoch 717/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.8695 - val_accuracy: 0.8861\n",
            "Epoch 718/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 9.1391e-04 - accuracy: 1.0000 - val_loss: 0.6954 - val_accuracy: 0.9114\n",
            "Epoch 719/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 5.4662e-04 - accuracy: 1.0000 - val_loss: 0.6850 - val_accuracy: 0.9198\n",
            "Epoch 720/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.8120e-04 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.9156\n",
            "Epoch 721/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.2452e-04 - accuracy: 1.0000 - val_loss: 0.6933 - val_accuracy: 0.9241\n",
            "Epoch 722/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.6673 - val_accuracy: 0.9241\n",
            "Epoch 723/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.0431e-04 - accuracy: 1.0000 - val_loss: 0.6780 - val_accuracy: 0.9241\n",
            "Epoch 724/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 9.7755e-05 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.9283\n",
            "Epoch 725/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.4444e-04 - accuracy: 1.0000 - val_loss: 0.6882 - val_accuracy: 0.9283\n",
            "Epoch 726/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.8502e-04 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.9198\n",
            "Epoch 727/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.9198\n",
            "Epoch 728/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.7060e-05 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.9198\n",
            "Epoch 729/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 3.7600e-05 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.9198\n",
            "Epoch 730/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.1443e-05 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.9198\n",
            "Epoch 731/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.6964e-05 - accuracy: 1.0000 - val_loss: 0.7060 - val_accuracy: 0.9198\n",
            "Epoch 732/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.3311e-05 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.9283\n",
            "Epoch 733/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.4000e-05 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.9325\n",
            "Epoch 734/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 4.6905e-05 - accuracy: 1.0000 - val_loss: 0.7093 - val_accuracy: 0.9325\n",
            "Epoch 735/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 5.9859e-05 - accuracy: 1.0000 - val_loss: 0.7129 - val_accuracy: 0.9325\n",
            "Epoch 736/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.3125e-05 - accuracy: 1.0000 - val_loss: 0.7145 - val_accuracy: 0.9325\n",
            "Epoch 737/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.6459e-05 - accuracy: 1.0000 - val_loss: 0.7169 - val_accuracy: 0.9325\n",
            "Epoch 738/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 9.9611e-06 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.9325\n",
            "Epoch 739/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.3117e-05 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.9325\n",
            "Epoch 740/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.1711e-05 - accuracy: 1.0000 - val_loss: 0.7206 - val_accuracy: 0.9325\n",
            "Epoch 741/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.7023e-05 - accuracy: 1.0000 - val_loss: 0.7225 - val_accuracy: 0.9325\n",
            "Epoch 742/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 7.7583e-06 - accuracy: 1.0000 - val_loss: 0.7236 - val_accuracy: 0.9325\n",
            "Epoch 743/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.9424e-05 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 0.9325\n",
            "Epoch 744/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 5.1741e-06 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.9325\n",
            "Epoch 745/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.5577e-05 - accuracy: 1.0000 - val_loss: 0.7313 - val_accuracy: 0.9325\n",
            "Epoch 746/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.3225e-05 - accuracy: 1.0000 - val_loss: 0.7334 - val_accuracy: 0.9325\n",
            "Epoch 747/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.0735e-05 - accuracy: 1.0000 - val_loss: 0.7344 - val_accuracy: 0.9325\n",
            "Epoch 748/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 7.9975e-06 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.9325\n",
            "Epoch 749/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.8746e-05 - accuracy: 1.0000 - val_loss: 0.7373 - val_accuracy: 0.9367\n",
            "Epoch 750/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.1999e-05 - accuracy: 1.0000 - val_loss: 0.7412 - val_accuracy: 0.9325\n",
            "Epoch 751/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.0588e-04 - accuracy: 1.0000 - val_loss: 0.7756 - val_accuracy: 0.9367\n",
            "Epoch 752/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.7998e-06 - accuracy: 1.0000 - val_loss: 0.8022 - val_accuracy: 0.9367\n",
            "Epoch 753/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 4.8938e-06 - accuracy: 1.0000 - val_loss: 0.8006 - val_accuracy: 0.9367\n",
            "Epoch 754/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 6.3213e-06 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.9325\n",
            "Epoch 755/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.5162e-05 - accuracy: 1.0000 - val_loss: 0.7926 - val_accuracy: 0.9325\n",
            "Epoch 756/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 8.2932e-06 - accuracy: 1.0000 - val_loss: 0.7903 - val_accuracy: 0.9325\n",
            "Epoch 757/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 1.3657 - val_accuracy: 0.7890\n",
            "Epoch 758/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 4.3749 - val_accuracy: 0.5865\n",
            "Epoch 759/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0315 - val_accuracy: 0.8523\n",
            "Epoch 760/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.5740e-05 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.8734\n",
            "Epoch 761/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.3293e-04 - accuracy: 1.0000 - val_loss: 0.7685 - val_accuracy: 0.8945\n",
            "Epoch 762/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.6704e-04 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.9198\n",
            "Epoch 763/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.5083e-05 - accuracy: 1.0000 - val_loss: 0.6688 - val_accuracy: 0.9283\n",
            "Epoch 764/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.8288e-06 - accuracy: 1.0000 - val_loss: 0.6553 - val_accuracy: 0.9283\n",
            "Epoch 765/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.8542e-06 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 0.9283\n",
            "Epoch 766/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.3149e-06 - accuracy: 1.0000 - val_loss: 0.6384 - val_accuracy: 0.9283\n",
            "Epoch 767/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.4117e-04 - accuracy: 1.0000 - val_loss: 0.6301 - val_accuracy: 0.9325\n",
            "Epoch 768/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.1325e-05 - accuracy: 1.0000 - val_loss: 0.6294 - val_accuracy: 0.9367\n",
            "Epoch 769/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 4.8557e-05 - accuracy: 1.0000 - val_loss: 0.6302 - val_accuracy: 0.9367\n",
            "Epoch 770/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 8.6028e-04 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.9325\n",
            "Epoch 771/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.6976e-05 - accuracy: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.9367\n",
            "Epoch 772/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.0005e-05 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.9367\n",
            "Epoch 773/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.2836e-05 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.9367\n",
            "Epoch 774/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 3.7206e-04 - accuracy: 1.0000 - val_loss: 0.6505 - val_accuracy: 0.9325\n",
            "Epoch 775/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.3862e-06 - accuracy: 1.0000 - val_loss: 0.6528 - val_accuracy: 0.9367\n",
            "Epoch 776/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 6.5480e-06 - accuracy: 1.0000 - val_loss: 0.6542 - val_accuracy: 0.9367\n",
            "Epoch 777/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 6.4299e-06 - accuracy: 1.0000 - val_loss: 0.6535 - val_accuracy: 0.9367\n",
            "Epoch 778/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.3190e-05 - accuracy: 1.0000 - val_loss: 0.6520 - val_accuracy: 0.9367\n",
            "Epoch 779/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 4.1325e-06 - accuracy: 1.0000 - val_loss: 0.6522 - val_accuracy: 0.9367\n",
            "Epoch 780/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.6726e-06 - accuracy: 1.0000 - val_loss: 0.6525 - val_accuracy: 0.9409\n",
            "Epoch 781/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.1333e-06 - accuracy: 1.0000 - val_loss: 0.6532 - val_accuracy: 0.9409\n",
            "Epoch 782/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 3.1979e-06 - accuracy: 1.0000 - val_loss: 0.6546 - val_accuracy: 0.9409\n",
            "Epoch 783/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 4.9168e-06 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.9409\n",
            "Epoch 784/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 4.4960e-06 - accuracy: 1.0000 - val_loss: 0.6576 - val_accuracy: 0.9409\n",
            "Epoch 785/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 9.9373e-06 - accuracy: 1.0000 - val_loss: 0.6612 - val_accuracy: 0.9409\n",
            "Epoch 786/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.8034e-06 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.9409\n",
            "Epoch 787/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 4.3173e-04 - accuracy: 1.0000 - val_loss: 0.7489 - val_accuracy: 0.9156\n",
            "Epoch 788/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 1.0615 - val_accuracy: 0.8861\n",
            "Epoch 789/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 1.1212 - val_accuracy: 0.8945\n",
            "Epoch 790/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8234 - val_accuracy: 0.9114\n",
            "Epoch 791/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.8716 - val_accuracy: 0.9114\n",
            "Epoch 792/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 0.0105 - accuracy: 0.9955 - val_loss: 2.6127 - val_accuracy: 0.8186\n",
            "Epoch 793/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 7.2277 - val_accuracy: 0.6118\n",
            "Epoch 794/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 5.0109 - val_accuracy: 0.6582\n",
            "Epoch 795/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 8.2319e-04 - accuracy: 1.0000 - val_loss: 4.4626 - val_accuracy: 0.6793\n",
            "Epoch 796/1000\n",
            "13/13 [==============================] - 3s 228ms/step - loss: 7.2734e-04 - accuracy: 1.0000 - val_loss: 3.0394 - val_accuracy: 0.7764\n",
            "Epoch 797/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 7.8044e-05 - accuracy: 1.0000 - val_loss: 2.3991 - val_accuracy: 0.8354\n",
            "Epoch 798/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 6.4835e-05 - accuracy: 1.0000 - val_loss: 2.0977 - val_accuracy: 0.8523\n",
            "Epoch 799/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.0105e-05 - accuracy: 1.0000 - val_loss: 1.8821 - val_accuracy: 0.8692\n",
            "Epoch 800/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.0059e-05 - accuracy: 1.0000 - val_loss: 1.7481 - val_accuracy: 0.8903\n",
            "Epoch 801/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.7888e-06 - accuracy: 1.0000 - val_loss: 1.6543 - val_accuracy: 0.8903\n",
            "Epoch 802/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.4351e-04 - accuracy: 1.0000 - val_loss: 1.5258 - val_accuracy: 0.8903\n",
            "Epoch 803/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 5.5897e-05 - accuracy: 1.0000 - val_loss: 1.4338 - val_accuracy: 0.8987\n",
            "Epoch 804/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 8.5800e-06 - accuracy: 1.0000 - val_loss: 1.3651 - val_accuracy: 0.9072\n",
            "Epoch 805/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 5.7701e-06 - accuracy: 1.0000 - val_loss: 1.3193 - val_accuracy: 0.9072\n",
            "Epoch 806/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 5.8435e-05 - accuracy: 1.0000 - val_loss: 1.2720 - val_accuracy: 0.9114\n",
            "Epoch 807/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.7733e-06 - accuracy: 1.0000 - val_loss: 1.2332 - val_accuracy: 0.9114\n",
            "Epoch 808/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 5.5517e-06 - accuracy: 1.0000 - val_loss: 1.2050 - val_accuracy: 0.9241\n",
            "Epoch 809/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 9.9104e-05 - accuracy: 1.0000 - val_loss: 1.1847 - val_accuracy: 0.9241\n",
            "Epoch 810/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.2788e-06 - accuracy: 1.0000 - val_loss: 1.1755 - val_accuracy: 0.9241\n",
            "Epoch 811/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.7159e-06 - accuracy: 1.0000 - val_loss: 1.1660 - val_accuracy: 0.9198\n",
            "Epoch 812/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.9467 - val_accuracy: 0.9241\n",
            "Epoch 813/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.8861e-04 - accuracy: 1.0000 - val_loss: 0.8545 - val_accuracy: 0.9114\n",
            "Epoch 814/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 1.5712 - val_accuracy: 0.8523\n",
            "Epoch 815/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0130 - accuracy: 0.9924 - val_loss: 1.0950 - val_accuracy: 0.9072\n",
            "Epoch 816/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0070 - accuracy: 0.9951 - val_loss: 1.5722 - val_accuracy: 0.7764\n",
            "Epoch 817/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0126 - accuracy: 0.9942 - val_loss: 1.1184 - val_accuracy: 0.8565\n",
            "Epoch 818/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9499 - val_accuracy: 0.8945\n",
            "Epoch 819/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 1.0314 - val_accuracy: 0.9072\n",
            "Epoch 820/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.7207e-04 - accuracy: 1.0000 - val_loss: 1.1429 - val_accuracy: 0.9030\n",
            "Epoch 821/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.0085e-04 - accuracy: 1.0000 - val_loss: 1.1197 - val_accuracy: 0.9072\n",
            "Epoch 822/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.2049e-04 - accuracy: 1.0000 - val_loss: 1.0910 - val_accuracy: 0.9156\n",
            "Epoch 823/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3232 - val_accuracy: 0.8903\n",
            "Epoch 824/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 1.3696 - val_accuracy: 0.8650\n",
            "Epoch 825/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.6723e-04 - accuracy: 1.0000 - val_loss: 1.3917 - val_accuracy: 0.8692\n",
            "Epoch 826/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 7.1584e-04 - accuracy: 1.0000 - val_loss: 1.3307 - val_accuracy: 0.8692\n",
            "Epoch 827/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 8.5403e-05 - accuracy: 1.0000 - val_loss: 1.2609 - val_accuracy: 0.8734\n",
            "Epoch 828/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.4569e-04 - accuracy: 1.0000 - val_loss: 1.0759 - val_accuracy: 0.8903\n",
            "Epoch 829/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 1.1046 - val_accuracy: 0.9030\n",
            "Epoch 830/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0305 - accuracy: 0.9949 - val_loss: 1.3516 - val_accuracy: 0.8861\n",
            "Epoch 831/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0082 - accuracy: 0.9990 - val_loss: 0.9100 - val_accuracy: 0.8987\n",
            "Epoch 832/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0078 - accuracy: 0.9955 - val_loss: 0.8048 - val_accuracy: 0.9114\n",
            "Epoch 833/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 1.0693 - val_accuracy: 0.9030\n",
            "Epoch 834/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 1.3390 - val_accuracy: 0.8734\n",
            "Epoch 835/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0401 - accuracy: 0.9978 - val_loss: 1.1437 - val_accuracy: 0.8692\n",
            "Epoch 836/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.0491 - val_accuracy: 0.8903\n",
            "Epoch 837/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 0.9358 - val_accuracy: 0.9072\n",
            "Epoch 838/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 0.0222 - accuracy: 0.9964 - val_loss: 0.8366 - val_accuracy: 0.9198\n",
            "Epoch 839/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0040 - accuracy: 0.9973 - val_loss: 0.6771 - val_accuracy: 0.9030\n",
            "Epoch 840/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.4297e-04 - accuracy: 1.0000 - val_loss: 0.6480 - val_accuracy: 0.9114\n",
            "Epoch 841/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.1712e-04 - accuracy: 1.0000 - val_loss: 0.6658 - val_accuracy: 0.9156\n",
            "Epoch 842/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 7.5762e-04 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.9241\n",
            "Epoch 843/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.4920e-04 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.9241\n",
            "Epoch 844/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.9489e-04 - accuracy: 1.0000 - val_loss: 0.7294 - val_accuracy: 0.9198\n",
            "Epoch 845/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.6374e-04 - accuracy: 1.0000 - val_loss: 0.7325 - val_accuracy: 0.9198\n",
            "Epoch 846/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 9.4005e-05 - accuracy: 1.0000 - val_loss: 0.7345 - val_accuracy: 0.9198\n",
            "Epoch 847/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.2279e-04 - accuracy: 1.0000 - val_loss: 0.7356 - val_accuracy: 0.9198\n",
            "Epoch 848/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 4.1621e-05 - accuracy: 1.0000 - val_loss: 0.7357 - val_accuracy: 0.9198\n",
            "Epoch 849/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 1.0628e-04 - accuracy: 1.0000 - val_loss: 0.7544 - val_accuracy: 0.9198\n",
            "Epoch 850/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.3541e-04 - accuracy: 1.0000 - val_loss: 0.7827 - val_accuracy: 0.9198\n",
            "Epoch 851/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.5502e-05 - accuracy: 1.0000 - val_loss: 0.7947 - val_accuracy: 0.9198\n",
            "Epoch 852/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.5128e-05 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.9198\n",
            "Epoch 853/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 2.7455e-05 - accuracy: 1.0000 - val_loss: 0.7973 - val_accuracy: 0.9198\n",
            "Epoch 854/1000\n",
            "13/13 [==============================] - 3s 228ms/step - loss: 3.1869e-05 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.9198\n",
            "Epoch 855/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.2609e-05 - accuracy: 1.0000 - val_loss: 0.7956 - val_accuracy: 0.9198\n",
            "Epoch 856/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.3349e-05 - accuracy: 1.0000 - val_loss: 0.7980 - val_accuracy: 0.9198\n",
            "Epoch 857/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 2.6628e-05 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.9198\n",
            "Epoch 858/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.0577e-05 - accuracy: 1.0000 - val_loss: 0.7980 - val_accuracy: 0.9198\n",
            "Epoch 859/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 9.9329e-06 - accuracy: 1.0000 - val_loss: 0.7962 - val_accuracy: 0.9198\n",
            "Epoch 860/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.8980e-04 - accuracy: 1.0000 - val_loss: 0.8247 - val_accuracy: 0.9198\n",
            "Epoch 861/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.4176e-05 - accuracy: 1.0000 - val_loss: 0.8338 - val_accuracy: 0.9198\n",
            "Epoch 862/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 2.8664e-05 - accuracy: 1.0000 - val_loss: 0.8331 - val_accuracy: 0.9198\n",
            "Epoch 863/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 8.8738e-06 - accuracy: 1.0000 - val_loss: 0.8316 - val_accuracy: 0.9198\n",
            "Epoch 864/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0239 - accuracy: 0.9979 - val_loss: 0.8566 - val_accuracy: 0.9030\n",
            "Epoch 865/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 1.0580 - val_accuracy: 0.8861\n",
            "Epoch 866/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8534 - val_accuracy: 0.9114\n",
            "Epoch 867/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.7115e-04 - accuracy: 1.0000 - val_loss: 0.8117 - val_accuracy: 0.9156\n",
            "Epoch 868/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 9.6467e-05 - accuracy: 1.0000 - val_loss: 0.7997 - val_accuracy: 0.9198\n",
            "Epoch 869/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 5.3159e-04 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.9198\n",
            "Epoch 870/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.7338e-05 - accuracy: 1.0000 - val_loss: 0.8154 - val_accuracy: 0.9198\n",
            "Epoch 871/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 7.1642e-05 - accuracy: 1.0000 - val_loss: 0.8102 - val_accuracy: 0.9198\n",
            "Epoch 872/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 5.4899e-05 - accuracy: 1.0000 - val_loss: 0.8157 - val_accuracy: 0.9198\n",
            "Epoch 873/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 9.8813e-05 - accuracy: 1.0000 - val_loss: 0.8245 - val_accuracy: 0.9156\n",
            "Epoch 874/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 5.1957e-04 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.8987\n",
            "Epoch 875/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.8116e-04 - accuracy: 1.0000 - val_loss: 0.8696 - val_accuracy: 0.8987\n",
            "Epoch 876/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.1929e-04 - accuracy: 1.0000 - val_loss: 0.9206 - val_accuracy: 0.8987\n",
            "Epoch 877/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 2.5470e-05 - accuracy: 1.0000 - val_loss: 0.9537 - val_accuracy: 0.9030\n",
            "Epoch 878/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.9129e-05 - accuracy: 1.0000 - val_loss: 0.9724 - val_accuracy: 0.9072\n",
            "Epoch 879/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.4425e-05 - accuracy: 1.0000 - val_loss: 0.9906 - val_accuracy: 0.9072\n",
            "Epoch 880/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.0024e-05 - accuracy: 1.0000 - val_loss: 1.0105 - val_accuracy: 0.9114\n",
            "Epoch 881/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 9.8866e-06 - accuracy: 1.0000 - val_loss: 1.0231 - val_accuracy: 0.9114\n",
            "Epoch 882/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.1416e-04 - accuracy: 1.0000 - val_loss: 1.0662 - val_accuracy: 0.9114\n",
            "Epoch 883/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.5258e-05 - accuracy: 1.0000 - val_loss: 1.0842 - val_accuracy: 0.9114\n",
            "Epoch 884/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.2061e-05 - accuracy: 1.0000 - val_loss: 1.0939 - val_accuracy: 0.9114\n",
            "Epoch 885/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 3.7295e-06 - accuracy: 1.0000 - val_loss: 1.1029 - val_accuracy: 0.9114\n",
            "Epoch 886/1000\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 1.8014e-04 - accuracy: 1.0000 - val_loss: 1.1452 - val_accuracy: 0.8987\n",
            "Epoch 887/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.6963e-05 - accuracy: 1.0000 - val_loss: 1.2274 - val_accuracy: 0.8861\n",
            "Epoch 888/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.1965e-05 - accuracy: 1.0000 - val_loss: 1.2511 - val_accuracy: 0.8861\n",
            "Epoch 889/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 4.2381e-05 - accuracy: 1.0000 - val_loss: 1.2402 - val_accuracy: 0.8945\n",
            "Epoch 890/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 3.9021e-05 - accuracy: 1.0000 - val_loss: 1.2496 - val_accuracy: 0.8987\n",
            "Epoch 891/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.9606e-05 - accuracy: 1.0000 - val_loss: 1.2438 - val_accuracy: 0.9072\n",
            "Epoch 892/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 1.2686e-06 - accuracy: 1.0000 - val_loss: 1.2485 - val_accuracy: 0.9072\n",
            "Epoch 893/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 9.0375e-07 - accuracy: 1.0000 - val_loss: 1.2494 - val_accuracy: 0.9114\n",
            "Epoch 894/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.0155e-04 - accuracy: 1.0000 - val_loss: 1.2626 - val_accuracy: 0.9114\n",
            "Epoch 895/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.7465e-06 - accuracy: 1.0000 - val_loss: 1.2679 - val_accuracy: 0.9114\n",
            "Epoch 896/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 2.2692e-04 - accuracy: 0.9997 - val_loss: 1.2659 - val_accuracy: 0.9114\n",
            "Epoch 897/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 9.5588e-07 - accuracy: 1.0000 - val_loss: 1.3114 - val_accuracy: 0.8903\n",
            "Epoch 898/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 2.0852e-06 - accuracy: 1.0000 - val_loss: 1.3397 - val_accuracy: 0.8903\n",
            "Epoch 899/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.1773e-06 - accuracy: 1.0000 - val_loss: 1.3372 - val_accuracy: 0.8903\n",
            "Epoch 900/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 3.7128e-06 - accuracy: 1.0000 - val_loss: 1.3296 - val_accuracy: 0.8903\n",
            "Epoch 901/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 5.6802e-06 - accuracy: 1.0000 - val_loss: 1.3240 - val_accuracy: 0.8903\n",
            "Epoch 902/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.0472e-06 - accuracy: 1.0000 - val_loss: 1.3173 - val_accuracy: 0.8903\n",
            "Epoch 903/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 7.4325e-07 - accuracy: 1.0000 - val_loss: 1.3094 - val_accuracy: 0.8945\n",
            "Epoch 904/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.4260e-06 - accuracy: 1.0000 - val_loss: 1.3029 - val_accuracy: 0.8945\n",
            "Epoch 905/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 9.8398e-04 - accuracy: 0.9990 - val_loss: 1.2400 - val_accuracy: 0.9114\n",
            "Epoch 906/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.6815e-04 - accuracy: 1.0000 - val_loss: 1.4985 - val_accuracy: 0.8819\n",
            "Epoch 907/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 4.7476e-06 - accuracy: 1.0000 - val_loss: 1.4577 - val_accuracy: 0.8819\n",
            "Epoch 908/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0459 - accuracy: 0.9914 - val_loss: 4.2236 - val_accuracy: 0.7932\n",
            "Epoch 909/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 2.7962 - val_accuracy: 0.7890\n",
            "Epoch 910/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0298 - accuracy: 0.9942 - val_loss: 1.3097 - val_accuracy: 0.8861\n",
            "Epoch 911/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.9086 - val_accuracy: 0.9156\n",
            "Epoch 912/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0139 - accuracy: 0.9930 - val_loss: 0.9058 - val_accuracy: 0.9072\n",
            "Epoch 913/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0030 - accuracy: 0.9986 - val_loss: 0.8696 - val_accuracy: 0.9114\n",
            "Epoch 914/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 9.6834e-04 - accuracy: 1.0000 - val_loss: 0.7739 - val_accuracy: 0.9114\n",
            "Epoch 915/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 4.0985e-04 - accuracy: 1.0000 - val_loss: 0.7400 - val_accuracy: 0.9241\n",
            "Epoch 916/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.6461e-04 - accuracy: 1.0000 - val_loss: 0.7300 - val_accuracy: 0.9198\n",
            "Epoch 917/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.7317e-04 - accuracy: 0.9998 - val_loss: 0.7032 - val_accuracy: 0.9198\n",
            "Epoch 918/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 7.6613e-04 - accuracy: 0.9993 - val_loss: 0.6741 - val_accuracy: 0.9198\n",
            "Epoch 919/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.2045e-04 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.9198\n",
            "Epoch 920/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.8821e-05 - accuracy: 1.0000 - val_loss: 0.6521 - val_accuracy: 0.9198\n",
            "Epoch 921/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.0089e-04 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 0.9198\n",
            "Epoch 922/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.2030e-04 - accuracy: 1.0000 - val_loss: 0.6367 - val_accuracy: 0.9198\n",
            "Epoch 923/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 8.3772e-05 - accuracy: 1.0000 - val_loss: 0.6283 - val_accuracy: 0.9241\n",
            "Epoch 924/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 8.1253e-05 - accuracy: 1.0000 - val_loss: 0.6252 - val_accuracy: 0.9283\n",
            "Epoch 925/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.1827e-05 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.9283\n",
            "Epoch 926/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.8925e-05 - accuracy: 1.0000 - val_loss: 0.6201 - val_accuracy: 0.9283\n",
            "Epoch 927/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.9691e-04 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.9283\n",
            "Epoch 928/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 3.5009e-05 - accuracy: 1.0000 - val_loss: 0.6032 - val_accuracy: 0.9283\n",
            "Epoch 929/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.4400e-04 - accuracy: 1.0000 - val_loss: 0.6012 - val_accuracy: 0.9283\n",
            "Epoch 930/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.1464e-05 - accuracy: 1.0000 - val_loss: 0.6007 - val_accuracy: 0.9283\n",
            "Epoch 931/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.5509e-05 - accuracy: 1.0000 - val_loss: 0.6019 - val_accuracy: 0.9283\n",
            "Epoch 932/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 4.6957e-05 - accuracy: 1.0000 - val_loss: 0.6040 - val_accuracy: 0.9283\n",
            "Epoch 933/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.8040e-05 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.9283\n",
            "Epoch 934/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 5.1187e-05 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.9283\n",
            "Epoch 935/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 4.1243e-05 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.9283\n",
            "Epoch 936/1000\n",
            "13/13 [==============================] - 3s 228ms/step - loss: 1.5279e-05 - accuracy: 1.0000 - val_loss: 0.6099 - val_accuracy: 0.9283\n",
            "Epoch 937/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.7146e-05 - accuracy: 1.0000 - val_loss: 0.6108 - val_accuracy: 0.9283\n",
            "Epoch 938/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 3.6253e-05 - accuracy: 1.0000 - val_loss: 0.6154 - val_accuracy: 0.9283\n",
            "Epoch 939/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.2820e-05 - accuracy: 1.0000 - val_loss: 0.6170 - val_accuracy: 0.9283\n",
            "Epoch 940/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 2.2278e-05 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.9283\n",
            "Epoch 941/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 2.9605e-05 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.9283\n",
            "Epoch 942/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 9.5628e-05 - accuracy: 1.0000 - val_loss: 0.6241 - val_accuracy: 0.9283\n",
            "Epoch 943/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 2.7073e-05 - accuracy: 1.0000 - val_loss: 0.6298 - val_accuracy: 0.9283\n",
            "Epoch 944/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 1.6433e-05 - accuracy: 1.0000 - val_loss: 0.6320 - val_accuracy: 0.9283\n",
            "Epoch 945/1000\n",
            "13/13 [==============================] - 3s 228ms/step - loss: 4.0875e-05 - accuracy: 1.0000 - val_loss: 0.6344 - val_accuracy: 0.9283\n",
            "Epoch 946/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 2.5451e-05 - accuracy: 1.0000 - val_loss: 0.6353 - val_accuracy: 0.9283\n",
            "Epoch 947/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.0799e-06 - accuracy: 1.0000 - val_loss: 0.6353 - val_accuracy: 0.9283\n",
            "Epoch 948/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.3954e-05 - accuracy: 1.0000 - val_loss: 0.6351 - val_accuracy: 0.9283\n",
            "Epoch 949/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 2.7687e-05 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.9283\n",
            "Epoch 950/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 2.8070e-05 - accuracy: 1.0000 - val_loss: 0.6370 - val_accuracy: 0.9283\n",
            "Epoch 951/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 9.8096e-06 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 0.9283\n",
            "Epoch 952/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 1.9463e-05 - accuracy: 1.0000 - val_loss: 0.6408 - val_accuracy: 0.9283\n",
            "Epoch 953/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.8516 - val_accuracy: 0.9114\n",
            "Epoch 954/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.8055 - val_accuracy: 0.9156\n",
            "Epoch 955/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 4.4360e-04 - accuracy: 1.0000 - val_loss: 0.7360 - val_accuracy: 0.9241\n",
            "Epoch 956/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 2.8747e-05 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.9283\n",
            "Epoch 957/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 2.1178e-05 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.9283\n",
            "Epoch 958/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 6.6014e-05 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.9283\n",
            "Epoch 959/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 2.4944e-05 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.9283\n",
            "Epoch 960/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 1.9704e-05 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.9283\n",
            "Epoch 961/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.7682e-04 - accuracy: 1.0000 - val_loss: 0.6647 - val_accuracy: 0.9283\n",
            "Epoch 962/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.9580e-06 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.9283\n",
            "Epoch 963/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.4219e-05 - accuracy: 1.0000 - val_loss: 0.6563 - val_accuracy: 0.9283\n",
            "Epoch 964/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 1.6402e-05 - accuracy: 1.0000 - val_loss: 0.6543 - val_accuracy: 0.9283\n",
            "Epoch 965/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 5.9613e-06 - accuracy: 1.0000 - val_loss: 0.6534 - val_accuracy: 0.9283\n",
            "Epoch 966/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.7555e-05 - accuracy: 1.0000 - val_loss: 0.6527 - val_accuracy: 0.9283\n",
            "Epoch 967/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 9.3718e-06 - accuracy: 1.0000 - val_loss: 0.6519 - val_accuracy: 0.9283\n",
            "Epoch 968/1000\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 4.2706e-06 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 0.9283\n",
            "Epoch 969/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.2337e-05 - accuracy: 1.0000 - val_loss: 0.6499 - val_accuracy: 0.9283\n",
            "Epoch 970/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.0866e-05 - accuracy: 1.0000 - val_loss: 0.6496 - val_accuracy: 0.9283\n",
            "Epoch 971/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.7357e-05 - accuracy: 1.0000 - val_loss: 0.6550 - val_accuracy: 0.9283\n",
            "Epoch 972/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 9.4076e-06 - accuracy: 1.0000 - val_loss: 0.6574 - val_accuracy: 0.9283\n",
            "Epoch 973/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 6.6538e-06 - accuracy: 1.0000 - val_loss: 0.6588 - val_accuracy: 0.9283\n",
            "Epoch 974/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.5307e-05 - accuracy: 1.0000 - val_loss: 0.6596 - val_accuracy: 0.9283\n",
            "Epoch 975/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.5632e-05 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 0.9283\n",
            "Epoch 976/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.3180e-06 - accuracy: 1.0000 - val_loss: 0.6604 - val_accuracy: 0.9325\n",
            "Epoch 977/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 7.9803e-06 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.9325\n",
            "Epoch 978/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 7.0962e-06 - accuracy: 1.0000 - val_loss: 0.6613 - val_accuracy: 0.9325\n",
            "Epoch 979/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.3540e-06 - accuracy: 1.0000 - val_loss: 0.6621 - val_accuracy: 0.9283\n",
            "Epoch 980/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.2415e-05 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.9283\n",
            "Epoch 981/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.6943e-06 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 0.9325\n",
            "Epoch 982/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 2.2873e-06 - accuracy: 1.0000 - val_loss: 0.6664 - val_accuracy: 0.9325\n",
            "Epoch 983/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.5098e-05 - accuracy: 1.0000 - val_loss: 0.6683 - val_accuracy: 0.9283\n",
            "Epoch 984/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 8.7908e-06 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.9283\n",
            "Epoch 985/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.3587e-06 - accuracy: 1.0000 - val_loss: 0.6728 - val_accuracy: 0.9283\n",
            "Epoch 986/1000\n",
            "13/13 [==============================] - 3s 228ms/step - loss: 2.4423e-06 - accuracy: 1.0000 - val_loss: 0.6745 - val_accuracy: 0.9283\n",
            "Epoch 987/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 5.2986e-06 - accuracy: 1.0000 - val_loss: 0.6734 - val_accuracy: 0.9283\n",
            "Epoch 988/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 4.3121e-06 - accuracy: 1.0000 - val_loss: 0.6745 - val_accuracy: 0.9283\n",
            "Epoch 989/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 2.6380e-05 - accuracy: 1.0000 - val_loss: 0.6795 - val_accuracy: 0.9283\n",
            "Epoch 990/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 5.5308e-06 - accuracy: 1.0000 - val_loss: 0.6799 - val_accuracy: 0.9283\n",
            "Epoch 991/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.7943e-06 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.9283\n",
            "Epoch 992/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 3.1714e-06 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.9283\n",
            "Epoch 993/1000\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.0221 - accuracy: 0.9950 - val_loss: 0.7620 - val_accuracy: 0.9156\n",
            "Epoch 994/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 4.7349e-05 - accuracy: 1.0000 - val_loss: 0.6505 - val_accuracy: 0.9325\n",
            "Epoch 995/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 4.9786e-04 - accuracy: 1.0000 - val_loss: 0.6118 - val_accuracy: 0.9367\n",
            "Epoch 996/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 3.5252e-05 - accuracy: 1.0000 - val_loss: 0.5943 - val_accuracy: 0.9409\n",
            "Epoch 997/1000\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 5.6032e-04 - accuracy: 1.0000 - val_loss: 0.5376 - val_accuracy: 0.9494\n",
            "Epoch 998/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.6300e-04 - accuracy: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.9451\n",
            "Epoch 999/1000\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 5.7406e-05 - accuracy: 1.0000 - val_loss: 0.5549 - val_accuracy: 0.9451\n",
            "Epoch 1000/1000\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 6.6782e-05 - accuracy: 1.0000 - val_loss: 0.5550 - val_accuracy: 0.9451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "zeRjoIllQN7C",
        "outputId": "17e1d83e-24f4-4402-b883-7fc7238e9216"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(H.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(H.history['accuracy'])\n",
        "plt.plot(H.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(H.history['loss'])\n",
        "plt.plot(H.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfsklEQVR4nO3dfZxWZb3v8c9XHEGUEAHdyoNQsQvUBB0Jt3XCbSI+BHY008TcbYvOfuWu9i5PsivdWeccd+1Xuk1TqTj2tNHyoU2GAT6lHUUZiRQfCHwoZjSZQFB8QNHf+WNdM665Zw3MDLPmhnu+79frfnGv61pr3b/FgvnNdf3WvZYiAjMzs0q7VTsAMzPbOTlBmJlZIScIMzMr5ARhZmaFnCDMzKyQE4SZmRVygjDrAZKulfSNTq77tKQP7uh+zMrmBGFmZoWcIMzMrJAThPUZaWrnfEkPSXpJ0g8k7S/pVkkvSrpN0pDc+jMkPSJpo6S7JI3P9U2StDxtdz0woOKzTpa0Im17r6T3dDPmT0laI2mDpAWSDkztknSppHWSXpD0sKRDUt+Jkh5NsTVJ+mK3/sKsz3OCsL7mVOA44K+BDwG3Av8CDCf7//BZAEl/DcwHPp/6FgK/lLSHpD2AXwA/BvYFfp72S9p2EjAP+DQwFLgGWCCpf1cClfS3wP8BTgcOAP4IXJe6pwH/LR3H4LTO+tT3A+DTETEIOAS4oyufa9ai5hKEpHnpt6qVnVj3n9NvWg9Jul3SQbm+X6ff/m4pN2LrZd+JiOciogm4B7g/In4XEa8CNwOT0nofBX4VEUsi4nXg34E9gb8BpgB1wGUR8XpE3AAsy33GbOCaiLg/It6IiB8CW9J2XXEWMC8ilkfEFmAOcJSkMcDrwCDg3YAi4rGIeDZt9zowQdLbIuL5iFjexc81A2owQQDXAtM7ue7vgPqIeA9wA/DNXN+3gLN7NjTbCTyXe/9KwfLe6f2BZL+xAxARbwJrgRGpryna3unyj7n3BwFfSL9gbJS0ERiVtuuKyhg2k40SRkTEHcAVwJXAOklzJb0trXoqcCLwR0m/kXRUFz/XDKjBBBERdwMb8m2S3pFGBA9KukfSu9O6d0bEy2m1pcDI3H5uB17srbhtp/MM2Q96IJvzJ/sh3wQ8C4xIbS1G596vBf5XROyTew2MiPk7GMNeZFNWTQARcXlEHAFMIJtqOj+1L4uImcB+ZFNhP+vi55oBNZggOjAX+Mf0n+mLwHcL1jmXbD7aDLIfqidJOlZSHfAFsmmie4H7gK3AZyXVSfrvwOTctt8D/oek96Zi8l6STpI0qIsxzAc+IWliql/8b7IpsaclHZn2Xwe8BLwKvJlqJGdJGpymxl4A3tyBvwfrw3avdgBlk7Q32bzxz3O/8PWvWGcWUA98oHejs51VRKxK/y6+QzattAL4UES8BpCSwveAb5AVsG/Kbdsg6VNkU0DjyKaufgvc3cUYbpP0VeBGYAhZcjojdb8NuBR4O1lyWEQ2LQrZ1OgVkvoBq8hqGWZdplp8YFAq4t0SEYekedlVEXFAB+t+kOyHwAciYl1F31TgixFxcrkRm5ntfGp+iikiXgCekvQRaL1+/LD0fhLZJYgzKpODmVlfV3MjCEnzganAMLIrVC4iuw78KrJryeuA6yLiYkm3AYeSFR0B/hQRM9J+7iG7hHBvsitHzo2IRb14KGZmVVVzCcLMzHpGzU8xmZlZ99TUVUzDhg2LMWPGVDsMM7NdxoMPPviXiBhe1FdTCWLMmDE0NDRUOwwzs12GpD921OcpJjMzK+QEYWZmhZwgzMysUE3VIIq8/vrrNDY28uqrr1Y7lFINGDCAkSNHUldXV+1QzKxG1HyCaGxsZNCgQYwZM4a2N9+sHRHB+vXraWxsZOzYsdUOx8xqRM1PMb366qsMHTq0ZpMDgCSGDh1a86MkM+tdNZ8ggJpODi36wjGaWe/qEwliu178M7z6QrWjMDPbqZSWICSNknRneubzI5I+V7COJF0uaU16LvThub5zJK1Or3PKihOAzc/BlnIeHrdx40a++92i5xNt24knnsjGjRtLiMjMrHPKHEFsBb4QERPIHtb+GUkTKtY5geyBKuPIHvR+FYCkfcnuwvpesid1XSRpSImxlqajBLF169Ztbrdw4UL22WefssIyM9uu0hJERDwbEcvT+xeBx8iezJU3E/hRZJYC+0g6ADgeWBIRGyLieWAJML2sWMt0wQUX8MQTTzBx4kSOPPJI3v/+9zNjxgwmTMhy5SmnnMIRRxzBwQcfzNy5c1u3GzNmDH/5y194+umnGT9+PJ/61Kc4+OCDmTZtGq+88kq1DsfM+pBeucw1PeFtEnB/RdcIsge8t2hMbR2175Cv/fIRHn2moNbw2mbo9zz0+1OX9znhwLdx0YcO7rD/kksuYeXKlaxYsYK77rqLk046iZUrV7Zejjpv3jz23XdfXnnlFY488khOPfVUhg4d2mYfq1evZv78+Xzve9/j9NNP58Ybb2TWrFldjtXMrCtKL1KnZ0LfCHw+Pd2tp/c/W1KDpIbm5uae3n2Pmzx5cpvvKlx++eUcdthhTJkyhbVr17J69ep224wdO5aJEycCcMQRR/D000/3Vrhm1oeVOoKQVEeWHH4aETcVrNIEjMotj0xtTWRPhcu331X0GRExF5gLUF9fv82nH3X4m/6zv4eBw2DwDg9StmuvvfZqfX/XXXdx2223cd999zFw4ECmTp1a+F2G/v37t77v16+fp5jMrFeUeRWTgB8Aj0XEtztYbQHw8XQ10xRgU0Q8CywCpkkakorT01LbLmfQoEG8+GLxFVKbNm1iyJAhDBw4kMcff5ylS5f2cnRmZh0rcwRxNHA28LCkFantX4DRABFxNbAQOBFYA7wMfCL1bZD0dWBZ2u7iiNhQYqxAOY9eHTp0KEcffTSHHHIIe+65J/vvv39r3/Tp07n66qsZP34873rXu5gyZUopMZiZdUdNPZO6vr4+Kh8Y9NhjjzF+/Phtb/js72HgUBg8ssToytepYzUzy5H0YETUF/X5m9RmZlbICQIA38fIzKySE4SZmRVygjAzs0JOEGZmVsgJwszMCjlBlKy7t/sGuOyyy3j55Zd7OCIzs85xgiiZE4SZ7ap65W6ufVn+dt/HHXcc++23Hz/72c/YsmULH/7wh/na177GSy+9xOmnn05jYyNvvPEGX/3qV3nuued45plnOOaYYxg2bBh33nlntQ/FzPqYvpUgbr0A/vxw+/bXNkO/OujXv33f9vzVoXDCJR1252/3vXjxYm644QYeeOABIoIZM2Zw991309zczIEHHsivfvUrILtH0+DBg/n2t7/NnXfeybBhw7oel5nZDvIUU6vybzmyePFiFi9ezKRJkzj88MN5/PHHWb16NYceeihLlizhS1/6Evfccw+DBw8uPRYzs+3pWyOIjn7Tf/YhGDgEBo8q7u8hEcGcOXP49Kc/3a5v+fLlLFy4kK985Ssce+yxXHjhhaXGYma2PR5BlCx/u+/jjz+eefPmsXnzZgCamppYt24dzzzzDAMHDmTWrFmcf/75LF++vN22Zma9rW+NILalpBmm/O2+TzjhBD72sY9x1FFHAbD33nvzk5/8hDVr1nD++eez2267UVdXx1VXXQXA7NmzmT59OgceeKCL1GbW63y7b8immPYcAvuUO8VUNt/u28y6yrf7NjOzLittiknSPOBkYF1EHFLQfz5wVi6O8cDw9DS5p4EXgTeArR1ltx4MttTdm5ntisocQVwLTO+oMyK+FRETI2IiMAf4TcVjRY9J/TucHGppGq0jfeEYzax3lZYgIuJuoLPPkT4TmF9GHAMGDGD9+vU1/QM0Ili/fj0DBgyodihmVkOqfhWTpIFkI43zcs0BLJYUwDURMXcb288GZgOMHj26Xf/IkSNpbGykubm54yA2PQd7vAB7bu7WMewMBgwYwMiRu/Yztc1s51L1BAF8CPh/FdNL74uIJkn7AUskPZ5GJO2k5DEXsquYKvvr6uoYO3bstiP45skwYQacfGl3j8HMrObsDFcxnUHF9FJENKU/1wE3A5OrEJeZWZ9W1QQhaTDwAeC/cm17SRrU8h6YBqwsOZBSd29mtisq8zLX+cBUYJikRuAioA4gIq5Oq30YWBwRL+U23R+4WdkP7d2B/4yIX5cVZ6saLmKbmXVHaQkiIs7sxDrXkl0Om297EjisnKg64hGEmVmlnaEGsZPwCMLMLM8JwszMCjlBgIvUZmYFnCBauEhtZtaGEwTgIrWZWXtOEGZmVsgJopWnmMzM8pwgwEVqM7MCThAtXKQ2M2vDCQJwkdrMrD0nCDMzK+QE0cpTTGZmeU4Q4CK1mVkBJ4gWHkCYmbXhBAG4SG1m1l5pCULSPEnrJBU+DU7SVEmbJK1IrwtzfdMlrZK0RtIFZcVoZmYdK3MEcS0wfTvr3BMRE9PrYgBJ/YArgROACcCZkiaUGGfiOSYzs7zSEkRE3A1s6Mamk4E1EfFkRLwGXAfM7NHgKrlIbWbWTrVrEEdJ+r2kWyUdnNpGAGtz6zSmtkKSZktqkNTQ3Nzc/Uj8TWozszaqmSCWAwdFxGHAd4BfdGcnETE3Iuojon748OHdDMUjCDOzSlVLEBHxQkRsTu8XAnWShgFNwKjcqiNTm5mZ9aKqJQhJfyVlk/+SJqdY1gPLgHGSxkraAzgDWFB+RJ5iMjPL272sHUuaD0wFhklqBC4C6gAi4mrgNOAfJG0FXgHOiIgAtko6D1gE9APmRcQjZcWZBVvq3s3MdkmlJYiIOHM7/VcAV3TQtxBYWEZc2wioVz/OzGxnV+2rmMzMbCflBAF4jsnMrD0niFaeYjIzy3OCAH+T2sysgBNECxepzczacIIwM7NCThCAi9RmZu05QbTyFJOZWZ4TBLhIbWZWwAmihYvUZmZtOEGYmVkhJwjARWozs/acIFp5isnMLM8JAlykNjMr4ATRwkVqM7M2SksQkuZJWidpZQf9Z0l6SNLDku6VdFiu7+nUvkJSQ1kxmplZx8ocQVwLTN9G/1PAByLiUODrwNyK/mMiYmJE1JcUX46nmMzMKpX5RLm7JY3ZRv+9ucWlwMiyYukcTzGZmeXtLDWIc4Fbc8sBLJb0oKTZ29pQ0mxJDZIampubu/fpLlKbmbVT2giisyQdQ5Yg3pdrfl9ENEnaD1gi6fGIuLto+4iYS5qeqq+v9zDAzKyHVHUEIek9wPeBmRGxvqU9IprSn+uAm4HJpQfjq5jMzNqoWoKQNBq4CTg7Iv6Qa99L0qCW98A0oPBKqB6Mptzdm5ntgkqbYpI0H5gKDJPUCFwE1AFExNXAhcBQ4LvKagBb0xVL+wM3p7bdgf+MiF+XFedbPIIwM8sr8yqmM7fT/0ngkwXtTwKHtd+iRC5Sm5m1s7NcxWRmZjsZJ4gWLlKbmbXhBAG4SG1m1p4TRCuPIMzM8pwgwEVqM7MCThBmZlbICaKFi9RmZm04QQAuUpuZtecEYWZmhZwgzMyskBME+ComM7MCnUoQkj4n6W3K/EDScknTyg6uV7lIbWbWRmdHEH8fES+Q3Xp7CHA2cElpUfU6jyDMzCp1NkG0/AQ9EfhxRDxCzf1U9QjCzCyvswniQUmLyRLEovRAnzfLC8vMzKqts8+DOBeYCDwZES9L2hf4RHlh9bIaGwuZmfWEzo4gjgJWRcRGSbOArwCbtreRpHmS1kkqfGRoKnpfLmmNpIckHZ7rO0fS6vQ6p5Nxdp+L1GZmbXQ2QVwFvCzpMOALwBPAjzqx3bXA9G30nwCMS6/Z6XNII5SLgPcCk4GLJA3pZKzd4CGEmVmlziaIrRERwEzgioi4Ehi0vY0i4m5gwzZWmQn8KDJLgX0kHQAcDyyJiA0R8TywhG0nmh7gEYSZWV5nE8SLkuaQXd76K0m7AXU98PkjgLW55cbU1lF7O5JmS2qQ1NDc3NwDIZmZGXQ+QXwU2EL2fYg/AyOBb5UWVRdExNyIqI+I+uHDh3dvJ/4mtZlZO51KECkp/BQYLOlk4NWI6EwNYnuagFG55ZGpraP28rhIbWbWRmdvtXE68ADwEeB04H5Jp/XA5y8APp6uZpoCbIqIZ4FFwDRJQ1JxelpqK4lHEGZmlTr7PYgvA0dGxDoAScOB24AbtrWRpPnAVGCYpEayK5PqACLiamAh2Zfv1gAvk75bEREbJH0dWJZ2dXFEbKvY3QM8gjAzy+tsgtitJTkk6+nE6CMiztxOfwCf6aBvHjCvk/GZmVkP62yC+LWkRcD8tPxRst/+a4OL1GZm7XQqQUTE+ZJOBY5OTXMj4ubywqoCF6nNzNro7AiCiLgRuLHEWKrIIwgzs0rbTBCSXqS4eiuyEsLbSonKzMyqbpsJIiK2ezuN2uEpJjOzPD+TGlykNjMr4ATRwkVqM7M2nCAAF6nNzNpzgjAzs0JOEK08xWRmlucEAS5Sm5kVcIJo4SK1mVkbThBmZlbICQLwVUxmZu05QbTyFJOZWV6pCULSdEmrJK2RdEFB/6WSVqTXHyRtzPW9ketbUGacLlKbmbXX6bu5dpWkfsCVwHFAI7BM0oKIeLRlnYj4p9z6/whMyu3ilYiYWFZ87bhIbWbWRpkjiMnAmoh4MiJeA64DZm5j/TN564FEZmZWZWUmiBHA2txyY2prR9JBwFjgjlzzAEkNkpZKOqWjD5E0O63X0Nzc3M1QPcVkZlZpZylSnwHcEBFv5NoOioh64GPAZZLeUbRhRMyNiPqIqB8+fPgOhOApJjOzvDITRBMwKrc8MrUVOYOK6aWIaEp/PgncRdv6RM9ykdrMrJ0yE8QyYJyksZL2IEsC7a5GkvRuYAhwX65tiKT+6f0wsmdhP1q5bY9ykdrMrI3SrmKKiK2SzgMWAf2AeRHxiKSLgYaIaEkWZwDXRbT5CT0euEbSm2RJ7JL81U9mZla+0hIEQEQsBBZWtF1YsfyvBdvdCxxaZmxteYrJzKzSzlKkNjOznYwTBLhIbWZWwAmihYvUZmZtOEGYmVkhJwjARWozs/acIFp5isnMLM8JAlykNjMr4ATRwkVqM7M2nCDMzKyQE4SZmRVygmjlKSYzszwnCHCR2sysgBNECxepzczacIIwM7NCThCAv0ltZtZeqQlC0nRJqyStkXRBQf/fSWqWtCK9PpnrO0fS6vQ6p8w4M55iMjPLK+2BQZL6AVcCxwGNwDJJCwqeDHd9RJxXse2+wEVAPdlP7gfTts+XFa+ZmbVV5ghiMrAmIp6MiNeA64CZndz2eGBJRGxISWEJML2kOH0Vk5lZgTITxAhgbW65MbVVOlXSQ5JukDSqi9siabakBkkNzc3N3Y/WVzGZmbVR7SL1L4ExEfEeslHCD7u6g4iYGxH1EVE/fPjwbobhEYSZWaUyE0QTMCq3PDK1tYqI9RGxJS1+Hziis9v2PI8gzMzyykwQy4BxksZK2gM4A1iQX0HSAbnFGcBj6f0iYJqkIZKGANNSm5mZ9ZLSrmKKiK2SziP7wd4PmBcRj0i6GGiIiAXAZyXNALYCG4C/S9tukPR1siQDcHFEbCgrVhepzczaKy1BAETEQmBhRduFufdzgDkdbDsPmFdmfBUf2GsfZWa2K6h2kXon4RGEmVklJ4hWHkGYmeU5QZiZWSEnCHCR2sysgBNECxepzczacIIAXKQ2M2vPCaKVRxBmZnlOEGZmVsgJAlykNjMr4ATRwkVqM7M2nCAAF6nNzNpzgmjlEYSZWZ4ThJmZFXKCABepzcwKOEG0cJHazKyNUhOEpOmSVklaI+mCgv5/lvSopIck3S7poFzfG5JWpNeCym17ONJyd29mtgsq7YFBkvoBVwLHAY3AMkkLIuLR3Gq/A+oj4mVJ/wB8E/ho6nslIiaWFV97HkGYmeWVOYKYDKyJiCcj4jXgOmBmfoWIuDMiXk6LS4GRJcZjZmZdUGaCGAGszS03praOnAvcmlseIKlB0lJJp5QRYCsXqc3M2in1mdSdJWkWUA98INd8UEQ0SXo7cIekhyPiiYJtZwOzAUaPHt39IDzDZGbWRpkjiCZgVG55ZGprQ9IHgS8DMyJiS0t7RDSlP58E7gImFX1IRMyNiPqIqB8+fHjPRW9m1seVmSCWAeMkjZW0B3AG0OZqJEmTgGvIksO6XPsQSf3T+2HA0UC+uN3DhIcQZmZtlTbFFBFbJZ0HLAL6AfMi4hFJFwMNEbEA+BawN/BzZXWAP0XEDGA8cI2kN8mS2CUVVz+ZmVnJSq1BRMRCYGFF24W59x/sYLt7gUPLjK0NF6nNzNrxN6lb+JvUZmZtOEGYmVkhJ4hWHkGYmeU5QZiZWSEnCHCR2sysgBNECxepzczacIIwM7NCThCAnwdhZtaeE0QrTzGZmeU5QYCL1GZmBZwgWrhIbWbWhhOEmZkVcoIAXKQ2M2vPCaKVp5jMzPKcIMBFajOzAk4QLVykNjNro9QEIWm6pFWS1ki6oKC/v6TrU//9ksbk+uak9lWSji8zTjMza6+0BCGpH3AlcAIwAThT0oSK1c4Fno+IdwKXAv+Wtp1A9gzrg4HpwHfT/sqKtrxdm5ntosp85OhkYE1EPAkg6TpgJpB/tvRM4F/T+xuAK5Q9nHomcF1EbAGekrQm7e++MgJd+cwm3v38Uzz7jd57yqmZWU95c8AQDvri3T2+3zITxAhgbW65EXhvR+tExFZJm4ChqX1pxbYjij5E0mxgNsDo0aO7FeiKoSex+ZUt3drWzKza9hgwhINK2G+ZCaJXRMRcYC5AfX19tyrNs2adSzbbZWZmLcosUjcBo3LLI1Nb4TqSdgcGA+s7ua2ZmZWozASxDBgnaaykPciKzgsq1lkAnJPenwbcERGR2s9IVzmNBcYBD5QYq5mZVShtiinVFM4DFgH9gHkR8Yiki4GGiFgA/AD4cSpCbyBLIqT1fkZW0N4KfCYi3igrVjMza09RQ18Qq6+vj4aGhmqHYWa2y5D0YETUF/X5m9RmZlbICcLMzAo5QZiZWSEnCDMzK1RTRWpJzcAfu7n5MOAvPRjOrsDH3Df4mGvfjhzvQRExvKijphLEjpDU0FElv1b5mPsGH3PtK+t4PcVkZmaFnCDMzKyQE8Rb5lY7gCrwMfcNPubaV8rxugZhZmaFPIIwM7NCThBmZlaozycISdMlrZK0RtIF1Y6np0gaJelOSY9KekTS51L7vpKWSFqd/hyS2iXp8vT38JCkw6t7BN0nqZ+k30m6JS2PlXR/Orbr0+3nSbeTvz613y9pTDXj7i5J+0i6QdLjkh6TdFStn2dJ/5T+Xa+UNF/SgFo7z5LmSVonaWWurcvnVdI5af3Vks4p+qyO9OkEIakfcCVwAjABOFPShOpG1WO2Al+IiAnAFOAz6dguAG6PiHHA7WkZsr+Dcek1G7iq90PuMZ8DHsst/xtwaUS8E3ietx4feC7wfGq/NK23K/oP4NcR8W7gMLJjr9nzLGkE8FmgPiIOIXucwBnU3nm+Fphe0dal8yppX+Aissc9TwYuakkqnRIRffYFHAUsyi3PAeZUO66SjvW/gOOAVcABqe0AYFV6fw1wZm791vV2pRfZ0wdvB/4WuAUQ2TdMd68852TPKjkqvd89radqH0MXj3cw8FRl3LV8nnnrWfb7pvN2C3B8LZ5nYAywsrvnFTgTuCbX3ma97b369AiCt/6htWhMbTUlDaknAfcD+0fEs6nrz8D+6X2t/F1cBvxP4M20PBTYGBFb03L+uFqPOfVvSuvvSsYCzcD/TdNq35e0FzV8niOiCfh34E/As2Tn7UFq+zy36Op53aHz3dcTRM2TtDdwI/D5iHgh3xfZrxQ1c52zpJOBdRHxYLVj6UW7A4cDV0XEJOAl3pp2AGryPA8BZpIlxwOBvWg/FVPzeuO89vUE0QSMyi2PTG01QVIdWXL4aUTclJqfk3RA6j8AWJfaa+Hv4mhghqSngevIppn+A9hHUsvjdfPH1XrMqX8wsL43A+4BjUBjRNyflm8gSxi1fJ4/CDwVEc0R8TpwE9m5r+Xz3KKr53WHzndfTxDLgHHp6oc9yApdC6ocU4+QJLJnfj8WEd/OdS0AWq5kOIesNtHS/vF0NcQUYFNuKLtLiIg5ETEyIsaQncs7IuIs4E7gtLRa5TG3/F2cltbfpX7Tjog/A2slvSs1HUv2LPeaPc9kU0tTJA1M/85bjrlmz3NOV8/rImCapCFp5DUttXVOtYsw1X4BJwJ/AJ4AvlzteHrwuN5HNvx8CFiRXieSzb3eDqwGbgP2TeuL7IquJ4CHya4Qqfpx7MDxTwVuSe/fDjwArAF+DvRP7QPS8prU//Zqx93NY50INKRz/QtgSK2fZ+BrwOPASuDHQP9aO8/AfLIay+tkI8Vzu3Negb9Px74G+ERXYvCtNszMrFBfn2IyM7MOOEGYmVkhJwgzMyvkBGFmZoWcIMzMrJAThNlOQNLUlrvPmu0snCDMzKyQE4RZF0iaJekBSSskXZOePbFZ0qXp+QS3Sxqe1p0oaWm6P//NuXv3v1PSbZJ+L2m5pHek3e+de67DT9O3hM2qxgnCrJMkjQc+ChwdEROBN4CzyG4W1xARBwO/Ibv/PsCPgC9FxHvIvt3a0v5T4MqIOAz4G7Jvy0J2x93Pkz2b5O1k9xcyq5rdt7+KmSXHAkcAy9Iv93uS3SztTeD6tM5PgJskDQb2iYjfpPYfAj+XNAgYERE3A0TEqwBpfw9ERGNaXkH2LIDfln9YZsWcIMw6T8API2JOm0bpqxXrdff+NVty79/A/z+tyjzFZNZ5twOnSdoPWp8PfBDZ/6OWu4h+DPhtRGwCnpf0/tR+NvCbiHgRaJR0StpHf0kDe/UozDrJv6GYdVJEPCrpK8BiSbuR3WXzM2QP6Zmc+taR1Skgux3z1SkBPAl8IrWfDVwj6eK0j4/04mGYdZrv5mq2gyRtjoi9qx2HWU/zFJOZmRXyCMLMzAp5BGFmZoWcIMzMrJAThJmZFXKCMDOzQk4QZmZW6P8DMsdsu5W62NwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEQvvmX_QV9n",
        "outputId": "42381378-1b94-4df4-c262-c06300fef0b3"
      },
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=56)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=lb.classes_))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       coast       0.92      0.94      0.93        90\n",
            "      forest       0.96      1.00      0.98        75\n",
            "     highway       0.96      0.89      0.92        72\n",
            "\n",
            "    accuracy                           0.95       237\n",
            "   macro avg       0.95      0.94      0.95       237\n",
            "weighted avg       0.95      0.95      0.94       237\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}